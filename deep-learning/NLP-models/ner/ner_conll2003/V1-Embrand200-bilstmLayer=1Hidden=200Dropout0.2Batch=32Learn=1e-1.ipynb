{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "from tqdm import tqdm\n",
    "import sklearn\n",
    "\n",
    "# np/pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import torchtext\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "# transformer\n",
    "from datasets import load_dataset\n",
    "\n",
    "# CRF\n",
    "from torchcrf import CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Config = {\n",
    "    'num_tags':9,\n",
    "    'num_layers':1,\n",
    "    'embedding_dim':200,\n",
    "    'vocab_size':23623,\n",
    "    'hidden_dim':100,\n",
    "    'batch_size':32\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 探查conll2003数据\n",
    "\n",
    "定义dataset，dataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset conll2003 (/root/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a58ebb0aeb404d77a227da495383f887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data_udpos = torchtext.datasets.UDPOS(root='./torchtext_datasets_udpos/', split=('train','valid','test'))\n",
    "dataset_conll2003 = load_dataset(\"conll2003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0',\n",
       " 'tokens': ['SOCCER',\n",
       "  '-',\n",
       "  'JAPAN',\n",
       "  'GET',\n",
       "  'LUCKY',\n",
       "  'WIN',\n",
       "  ',',\n",
       "  'CHINA',\n",
       "  'IN',\n",
       "  'SURPRISE',\n",
       "  'DEFEAT',\n",
       "  '.'],\n",
       " 'pos_tags': [21, 8, 22, 37, 22, 22, 6, 22, 15, 12, 21, 7],\n",
       " 'chunk_tags': [11, 0, 11, 21, 11, 12, 0, 11, 13, 11, 12, 0],\n",
       " 'ner_tags': [0, 0, 5, 0, 0, 0, 0, 1, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_conll2003['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_tag2id = {'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7, 'I-MISC': 8}\n",
    "\n",
    "ner_id2tag = {}\n",
    "for key in ner_tag2id.keys():\n",
    "    ner_id2tag[ner_tag2id[key]] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-PER',\n",
       " 2: 'I-PER',\n",
       " 3: 'B-ORG',\n",
       " 4: 'I-ORG',\n",
       " 5: 'B-LOC',\n",
       " 6: 'I-LOC',\n",
       " 7: 'B-MISC',\n",
       " 8: 'I-MISC'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_id2tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O'],\n",
       " ['ORG', 'O', 'MISC', 'O', 'O', 'O', 'MISC', 'O', 'O'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ner_id_to_tags(ner_id_seq):\n",
    "    res1, res2 = [], []\n",
    "    for ner_id in ner_id_seq:\n",
    "        res1.append(ner_id2tag.get(ner_id, ''))\n",
    "        res2.append(ner_id2tag.get(ner_id, '-').split('-')[-1])\n",
    "    return res1, res2\n",
    "\n",
    "ner_id_to_tags(dataset_conll2003['train'][0]['ner_tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length = 124\n"
     ]
    }
   ],
   "source": [
    "m = 0\n",
    "for k in dataset_conll2003.keys():\n",
    "    for i in dataset_conll2003[k]['tokens']:\n",
    "        m = max(m, len(i))\n",
    "print('max length = {}'.format(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30289\n"
     ]
    }
   ],
   "source": [
    "word_to_ix = {}\n",
    "for k in dataset_conll2003.keys():\n",
    "    for tokens in dataset_conll2003[k]['tokens']:\n",
    "        for token in tokens:\n",
    "            if token not in word_to_ix:\n",
    "                word_to_ix[token] = len(word_to_ix)\n",
    "                \n",
    "Config['vocab_size'] = len(word_to_ix)\n",
    "\n",
    "print(Config['vocab_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_word2ix(word_to_ix, token_list):\n",
    "    res = list()\n",
    "    for token in token_list:\n",
    "        res.append(word_to_ix.get(token, len(word_to_ix)+1))\n",
    "    return {'token_ids':res}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98/cache-e993f22e7c8f1977.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98/cache-9da2d1c0e9528511.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98/cache-586edb6c12fcdba7.arrow\n"
     ]
    }
   ],
   "source": [
    "dataset_conll2003_train=dataset_conll2003['train'].map(lambda x: func_word2ix(word_to_ix, x['tokens']))\n",
    "dataset_conll2003_train.set_format(type=\"torch\", columns=['token_ids','ner_tags'])\n",
    "\n",
    "dataset_conll2003_test=dataset_conll2003['test'].map(lambda x: func_word2ix(word_to_ix, x['tokens']))\n",
    "dataset_conll2003_test.set_format(type=\"torch\", columns=['token_ids','ner_tags'])\n",
    "\n",
    "dataset_conll2003_val=dataset_conll2003['validation'].map(lambda x: func_word2ix(word_to_ix, x['tokens']))\n",
    "dataset_conll2003_val.set_format(type=\"torch\", columns=['token_ids','ner_tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.token_ids = self.data['token_ids'] # 在这变成torch.tensor，但长度不同\n",
    "        self.ner_tags = self.data['ner_tags']\n",
    "        self.tokens = self.data['tokens']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "#         curr = dict()\n",
    "#         curr['token_ids'] = self.token_ids\n",
    "#         curr['ner_tags'] = self.ner_tags\n",
    "        return self.token_ids[index], self.ner_tags[index], self.tokens[index]\n",
    "\n",
    "\n",
    "def collate_fn_padd(batch):\n",
    "    '''\n",
    "    Padds batch of variable length\n",
    "\n",
    "    note: it converts things ToTensor manually here since the ToTensor transform\n",
    "    assume it takes in images rather than arbitrary tensors.\n",
    "    '''\n",
    "    x, y, z = zip(*batch)\n",
    "    x_lens = [len(x_i) for x_i in x]\n",
    "    y_lens = [len(y_i) for y_i in y]\n",
    "    x_pad = torch.nn.utils.rnn.pad_sequence(x, batch_first=True)\n",
    "    y_pad = torch.nn.utils.rnn.pad_sequence(y, batch_first=True)\n",
    "    return x_pad, torch.tensor(x_lens), y_pad, torch.tensor(y_lens), z\n",
    "    \n",
    "dataset_conll2003_train_loader = DataLoader(\n",
    "    MyDataset(dataset_conll2003_train),\n",
    "    batch_size=32,\n",
    "    shuffle=True, \n",
    "    collate_fn=lambda x: collate_fn_padd(x))\n",
    "\n",
    "\n",
    "dataset_conll2003_test_loader = DataLoader(\n",
    "    MyDataset(dataset_conll2003_test),\n",
    "    batch_size=32,\n",
    "    shuffle=True, \n",
    "    collate_fn=lambda x: collate_fn_padd(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['17',\n",
       " '-',\n",
       " 'Karina',\n",
       " 'Habsudova',\n",
       " '(',\n",
       " 'Slovakia',\n",
       " ')',\n",
       " 'beat',\n",
       " 'Nathalie',\n",
       " 'Dechy',\n",
       " '(',\n",
       " 'France',\n",
       " ')',\n",
       " '6-4',\n",
       " '6-2']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataset_conll2003_train_loader))[4][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14041 3453\n"
     ]
    }
   ],
   "source": [
    "print(dataset_conll2003_train_loader.dataset.__len__(), dataset_conll2003_test_loader.dataset.__len__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM_CRF(nn.Module):\n",
    "\n",
    "    def __init__(self, config=None):\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "        self.config = config\n",
    "\n",
    "        # BiLSTM-model 给 emission 层定义参数\n",
    "        self.embedding_dim = self.config.get('embedding_dim', 200)\n",
    "        self.hidden_dim = self.config.get('hidden_dim', 200)\n",
    "        self.vocab_size = self.config.get('vocab_size', 30289)\n",
    "\n",
    "        self.word_embeds = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.target_size = self.config.get('num_tags', 9)\n",
    "        self.num_layers = self.config.get('num_layers',1)\n",
    "        self.batch_size = self.config.get('batch_size',16)\n",
    "        self.bidirectional = True\n",
    "\n",
    "        # lstm\n",
    "        self.lstm = nn.LSTM(input_size=self.embedding_dim, hidden_size=self.hidden_dim//2,\n",
    "                            num_layers=self.num_layers, bidirectional=self.bidirectional)\n",
    "        self.hidden2tag1 = nn.Linear(self.hidden_dim, self.target_size*3)\n",
    "        self.hidden2tag2 = nn.Linear(self.target_size*3, self.target_size)\n",
    "        self.dropout020 = nn.Dropout(0.2)\n",
    "#         self.hidden_init = self.init_hidden()\n",
    "\n",
    "        # CRF-model\n",
    "        self.crf = CRF(self.config.get('num_tags', 9), batch_first=True)\n",
    "\n",
    "    def init_hidden(self):\n",
    "        hidden = torch.zeros(self.num_layers*2 if self.bidirectional else self.num_layers,\n",
    "                             self.batch_size, self.hidden_dim//2)\n",
    "        cell = torch.zeros(self.num_layers*2 if self.bidirectional else self.num_layers,\n",
    "                             self.batch_size, self.hidden_dim//2)\n",
    "        return hidden, cell\n",
    "\n",
    "    def forward(self, sent, sent_len):\n",
    "        \"\"\"\n",
    "\n",
    "        :param sent: 输入的已转换为token_id的句子，(batch_len * sent_len * token_emb_len)\n",
    "        :param sent_len: tensor(list(int))\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        embeds = self.word_embeds(sent)\n",
    "        embed_packed = pack_padded_sequence(embeds, lengths=sent_len.to('cpu'),\n",
    "                                            batch_first=True,\n",
    "                                            enforce_sorted=False)\n",
    "        lstm_out, (hidden, cell) = self.lstm(embed_packed) #, self.hidden_init)\n",
    "        lstm_out, lens = pad_packed_sequence(lstm_out, batch_first=True)\n",
    "        tag_score = self.hidden2tag1(lstm_out)\n",
    "        tag_score = self.dropout020(tag_score)\n",
    "        tag_score = self.hidden2tag2(tag_score)\n",
    "#         tag_score = nn.functional.softmax(tag_score, dim=-1)\n",
    "        return tag_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'V1-Embrand200-bilstmLayer=1Hidden=200Dropout0.2Batch=32Learn=1e-1'\n",
    "model_lstm = BiLSTM_CRF(config=Config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm = model_lstm.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of BiLSTM_CRF(\n",
       "  (word_embeds): Embedding(30289, 200)\n",
       "  (lstm): LSTM(200, 50, bidirectional=True)\n",
       "  (hidden2tag1): Linear(in_features=100, out_features=27, bias=True)\n",
       "  (hidden2tag2): Linear(in_features=27, out_features=9, bias=True)\n",
       "  (dropout020): Dropout(p=0.2, inplace=False)\n",
       "  (crf): CRF(num_tags=9)\n",
       ")>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lstm.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 3.5792683998664065), (0, 0.1334168085220698), (7, 6.580731691551936), (1, 3.4279629629629627), (2, 4.996589124460149), (5, 3.1687052598817305), (4, 6.108141348692104), (8, 19.58835978835979), (6, 19.554499183712664)]\n"
     ]
    }
   ],
   "source": [
    "# 手动计算验证权重\n",
    "import collections\n",
    "ner_tags_all = torch.cat(dataset_conll2003_train['ner_tags'])\n",
    "t=collections.Counter(ner_tags_all.numpy())\n",
    "res = []\n",
    "for k in t:\n",
    "    res.append((k, len(ner_tags_all)/9/t[k]))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1334,  3.4280,  4.9966,  3.5793,  6.1081,  3.1687, 19.5545,  6.5807,\n",
       "        19.5884])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights=sklearn.utils.class_weight.compute_class_weight(\n",
    "    class_weight='balanced',classes=np.unique(ner_tags_all),y=ner_tags_all.numpy())\n",
    "class_weights=torch.tensor(class_weights,dtype=torch.float)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model_lstm.parameters(), lr=1e-1)\n",
    "loss_fn = nn.CrossEntropyLoss(reduction='mean', weight=class_weights.cuda()) \n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_single_epoch(model, data_iter=None, optimizer=None, loss_fn=None, is_train=False):\n",
    "    if is_train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()   \n",
    "    correct_curr, correct_sum, loss_sum, loss_curr = 0, 0, 0, 0\n",
    "    loss_list, accuracy_list = [], []\n",
    "    print('Total (training) batch = {}'.format(len(data_iter)))\n",
    "    batch_i = 0\n",
    "    data_iter_len = data_iter.dataset.__len__() # total sample num.\n",
    "    batch_num = len(data_iter)\n",
    "    \n",
    "    batch_loss_list = list()\n",
    "    logits_list = list()\n",
    "    y_list, y_len_list = [], []\n",
    "    for batch_data in data_iter:\n",
    "        torch.cuda.empty_cache()\n",
    "        batch_i += 1\n",
    "        if is_train:\n",
    "            optimizer.zero_grad()\n",
    "#             model.zero_grad()\n",
    "        x, x_len, y, y_len, _ = batch_data\n",
    "        x = x.cuda()\n",
    "        x_len = x_len.cuda()\n",
    "        y = y.cuda()\n",
    "        # model predict \n",
    "        logits = model(x, x_len)\n",
    "        assert logits.shape[0:2]==x.shape[0:2]\n",
    "        # compute loss \n",
    "        batch_loss = 0\n",
    "        for i in range(logits.size(0)): # num of samples in one batch\n",
    "            loss = loss_fn(logits[i], y[i])\n",
    "            batch_loss += loss \n",
    "        \n",
    "        batch_loss /= logits.size(0)\n",
    "        if is_train:\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # 记录\n",
    "        batch_loss_list.append(batch_loss.item())\n",
    "        logits_list.append(logits)\n",
    "        y_list.append(y)\n",
    "        y_len_list.append(y_len)\n",
    "#         if batch_i%100==0:\n",
    "#             print(batch_loss.item())\n",
    "        \n",
    "        x = x.cpu()\n",
    "        x_len = x_len.cpu()\n",
    "        y = y.cpu()\n",
    "        \n",
    "#     print(sum(batch_loss_list)/batch_num)\n",
    "    return batch_loss_list, logits_list, y_list, y_len_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_cal_accu_recall(logits_list=None, y_list=None, y_len_list=None):\n",
    "    eval_dict = {'tp':0,'tn':0,'fp':0,'fn':0,'others':0,'n_total':0}\n",
    "    n_total = 0\n",
    "    for logit_i, logit in enumerate(logits_list):\n",
    "        assert logit.shape[0:2] == y_list[logit_i].shape\n",
    "        batch_len = len(y_len_list[logit_i])\n",
    "        batch_max_seqlen = max(y_len_list[logit_i])\n",
    "        y_curr = y_list[logit_i]\n",
    "        logit_argmax = torch.argmax(logit, dim=2)\n",
    "\n",
    "        # get mask matrix\n",
    "        mask = torch.zeros((batch_len, batch_max_seqlen))\n",
    "        for mask_i in range(mask.shape[0]):\n",
    "            mask[mask_i][0:y_len_list[logit_i][mask_i]] = 1\n",
    "        assert sum(mask.sum(axis=1)==y_len_list[logit_i])//batch_len==1\n",
    "\n",
    "        # cal the tp,tn,fp,fn in this batch\n",
    "        N = mask.sum()\n",
    "        TP = ((logit_argmax>0)*(y_curr>0)*(logit_argmax==y_curr)*mask.cuda()).sum()\n",
    "        TN = ((logit_argmax==0)*(y_curr==0)*(logit_argmax==y_curr)*mask.cuda()).sum()\n",
    "        FP = ((logit_argmax>0)*(y_curr==0)*(logit_argmax!=y_curr)*mask.cuda()).sum()\n",
    "        FN = ((logit_argmax==0)*(y_curr>0)*(logit_argmax!=y_curr)*mask.cuda()).sum()\n",
    "        others = ((logit_argmax>0)*(y_curr>0)*(logit_argmax!=y_curr)*mask.cuda()).sum()\n",
    "\n",
    "        eval_dict['tp'] += TP.item()\n",
    "        eval_dict['tn'] += TN.item()\n",
    "        eval_dict['fp'] += FP.item()\n",
    "        eval_dict['fn'] += FN.item()\n",
    "        eval_dict['others'] += others.item()\n",
    "        eval_dict['n_total'] += N.item()\n",
    "\n",
    "        accu = (TP+TN) / N\n",
    "        recall = TP / (TP + FN)\n",
    "#         print(accu, recall)\n",
    "    \n",
    "    if False:\n",
    "        print('Total accu = {:.2f}% recall = {:.2f}%'.format(\n",
    "            (eval_dict['tp'] + eval_dict['tn'])/eval_dict['n_total']*100, \n",
    "            eval_dict['tp']/(eval_dict['tp'] + eval_dict['fn'])*100))\n",
    "    return eval_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_eval(model, data_iter=None, loss_fn=None):\n",
    "    model.eval()\n",
    "    correct_curr, correct_sum, loss_sum, loss_curr = 0, 0, 0, 0\n",
    "    loss_list, accuracy_list = [], []\n",
    "    print('Total (training) batch = {}'.format(len(data_iter)))\n",
    "    batch_i = 0\n",
    "    data_iter_len = data_iter.dataset.__len__() # total sample num.\n",
    "    batch_num = len(data_iter)\n",
    "    \n",
    "    batch_loss_list = list()\n",
    "    logits_list = list()\n",
    "    y_list, y_len_list = [], []\n",
    "    for batch_data in data_iter:\n",
    "        batch_i += 1\n",
    "        x, x_len, y, y_len,_ = batch_data\n",
    "        x = x.cuda()\n",
    "        x_len = x_len.cuda()\n",
    "        y = y.cuda()\n",
    "        # model predict \n",
    "        logits = model(x, x_len)\n",
    "        assert logits.shape[0:2]==x.shape[0:2]\n",
    "        # compute loss \n",
    "        batch_loss = 0\n",
    "        for i in range(logits.size(0)): # num of samples in one batch\n",
    "            loss = loss_fn(logits[i], y[i])\n",
    "            batch_loss += loss \n",
    "        \n",
    "        batch_loss /= logits.size(0)\n",
    "        \n",
    "        # 记录\n",
    "        batch_loss_list.append(batch_loss.item())\n",
    "        logits_list.append(logits)\n",
    "        y_list.append(y)\n",
    "        y_len_list.append(y_len)\n",
    "#         if batch_i%100==0:\n",
    "#             print(batch_loss.item())\n",
    "        \n",
    "        x = x.cpu()\n",
    "        x_len = x_len.cpu()\n",
    "        y = y.cpu()\n",
    "        \n",
    "#     print(sum(batch_loss_list)/batch_num)\n",
    "    return batch_loss_list, logits_list, y_list, y_len_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练开始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Epoch = 0\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 1.47737321\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.32306615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  from ipykernel import kernelapp as app\n",
      "  2%|▏         | 1/50 [00:14<11:54, 14.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 61.93% recall = 54.59%\n",
      "Test :Total accu = 66.42% recall = 51.47%\n",
      "==================================================\n",
      "Epoch = 1\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 1.34920077\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.30786751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:29<11:38, 14.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 66.65% recall = 62.79%\n",
      "Test :Total accu = 66.44% recall = 60.12%\n",
      "==================================================\n",
      "Epoch = 2\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 1.22810090\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.23127040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [00:43<11:19, 14.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 69.19% recall = 68.70%\n",
      "Test :Total accu = 66.43% recall = 59.80%\n",
      "==================================================\n",
      "Epoch = 3\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 1.12699140\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.17240155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [00:58<11:06, 14.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 71.50% recall = 74.49%\n",
      "Test :Total accu = 70.05% recall = 69.99%\n",
      "==================================================\n",
      "Epoch = 4\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 1.02834336\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.11882982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [01:12<10:46, 14.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 74.71% recall = 79.21%\n",
      "Test :Total accu = 67.13% recall = 78.09%\n",
      "==================================================\n",
      "Epoch = 5\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.95345893\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.17005050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [01:26<10:31, 14.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 76.58% recall = 82.20%\n",
      "Test :Total accu = 71.55% recall = 70.41%\n",
      "==================================================\n",
      "Epoch = 6\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.88314902\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.08234139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [01:41<10:21, 14.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 77.93% recall = 84.36%\n",
      "Test :Total accu = 73.02% recall = 75.17%\n",
      "==================================================\n",
      "Epoch = 7\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.81084800\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.05042877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [01:55<10:07, 14.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 79.87% recall = 86.62%\n",
      "Test :Total accu = 73.65% recall = 77.84%\n",
      "==================================================\n",
      "Epoch = 8\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.76767864\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.06337513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [02:10<09:55, 14.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 81.03% recall = 88.58%\n",
      "Test :Total accu = 75.25% recall = 79.45%\n",
      "==================================================\n",
      "Epoch = 9\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.71411565\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.00159833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [02:24<09:39, 14.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 82.21% recall = 89.69%\n",
      "Test :Total accu = 76.57% recall = 79.34%\n",
      "==================================================\n",
      "Epoch = 10\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.65646292\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.02983023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [02:39<09:24, 14.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 84.02% recall = 91.27%\n",
      "Test :Total accu = 78.51% recall = 78.05%\n",
      "==================================================\n",
      "Epoch = 11\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.61907423\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.99718606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [02:53<09:07, 14.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 85.03% recall = 92.30%\n",
      "Test :Total accu = 77.18% recall = 83.73%\n",
      "==================================================\n",
      "Epoch = 12\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.57020208\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.98591107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [03:07<08:50, 14.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 86.03% recall = 93.30%\n",
      "Test :Total accu = 77.75% recall = 84.17%\n",
      "==================================================\n",
      "Epoch = 13\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.53250571\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.97710483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [03:21<08:35, 14.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 87.08% recall = 93.95%\n",
      "Test :Total accu = 78.37% recall = 84.52%\n",
      "==================================================\n",
      "Epoch = 14\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.49239215\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.96692959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [03:35<08:18, 14.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 87.90% recall = 94.76%\n",
      "Test :Total accu = 80.09% recall = 83.98%\n",
      "==================================================\n",
      "Epoch = 15\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.46029764\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.99440030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [03:49<08:02, 14.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 88.90% recall = 95.46%\n",
      "Test :Total accu = 80.37% recall = 83.23%\n",
      "==================================================\n",
      "Epoch = 16\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.42833661\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.00863572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [04:04<07:47, 14.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 89.64% recall = 95.84%\n",
      "Test :Total accu = 82.22% recall = 82.01%\n",
      "==================================================\n",
      "Epoch = 17\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.39981317\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.95762105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [04:18<07:36, 14.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 90.46% recall = 96.28%\n",
      "Test :Total accu = 81.88% recall = 84.73%\n",
      "==================================================\n",
      "Epoch = 18\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.37458333\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.99863272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [04:33<07:24, 14.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 90.81% recall = 96.53%\n",
      "Test :Total accu = 80.82% recall = 86.91%\n",
      "==================================================\n",
      "Epoch = 19\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.35741328\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.99089279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [04:47<07:10, 14.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 91.33% recall = 96.94%\n",
      "Test :Total accu = 81.77% recall = 85.50%\n",
      "==================================================\n",
      "Epoch = 20\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.33343834\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.99190164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [05:01<06:55, 14.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 91.96% recall = 97.18%\n",
      "Test :Total accu = 82.25% recall = 86.08%\n",
      "==================================================\n",
      "Epoch = 21\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.31725261\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.99123073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [05:15<06:40, 14.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 92.31% recall = 97.40%\n",
      "Test :Total accu = 82.63% recall = 86.58%\n",
      "==================================================\n",
      "Epoch = 22\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.30166959\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.99681492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [05:30<06:27, 14.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 92.72% recall = 97.67%\n",
      "Test :Total accu = 82.39% recall = 86.51%\n",
      "==================================================\n",
      "Epoch = 23\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.29028601\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.02036545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [05:44<06:13, 14.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 93.13% recall = 97.76%\n",
      "Test :Total accu = 83.06% recall = 85.19%\n",
      "==================================================\n",
      "Epoch = 24\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.28066212\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.01410912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [05:59<06:01, 14.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 93.34% recall = 97.94%\n",
      "Test :Total accu = 82.92% recall = 86.75%\n",
      "==================================================\n",
      "Epoch = 25\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.26817774\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.03993276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [06:13<05:46, 14.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 93.57% recall = 98.05%\n",
      "Test :Total accu = 83.66% recall = 85.38%\n",
      "==================================================\n",
      "Epoch = 26\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.26160829\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.02681889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [06:28<05:31, 14.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 93.80% recall = 98.10%\n",
      "Test :Total accu = 82.72% recall = 86.86%\n",
      "==================================================\n",
      "Epoch = 27\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.25630625\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.03793268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [06:43<05:19, 14.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 93.91% recall = 98.18%\n",
      "Test :Total accu = 83.43% recall = 85.81%\n",
      "==================================================\n",
      "Epoch = 28\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.25223152\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.02639717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [06:57<05:04, 14.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 94.04% recall = 98.11%\n",
      "Test :Total accu = 83.13% recall = 86.22%\n",
      "==================================================\n",
      "Epoch = 29\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.24762546\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.01222943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [07:11<04:47, 14.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 94.17% recall = 98.23%\n",
      "Test :Total accu = 83.42% recall = 86.11%\n",
      "==================================================\n",
      "Epoch = 30\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.24440253\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.01289203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [07:25<04:32, 14.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 94.23% recall = 98.24%\n",
      "Test :Total accu = 82.98% recall = 87.11%\n",
      "==================================================\n",
      "Epoch = 31\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.24133764\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.02579959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [07:40<04:17, 14.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 94.35% recall = 98.30%\n",
      "Test :Total accu = 83.04% recall = 87.35%\n",
      "==================================================\n",
      "Epoch = 32\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.24006433\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.00970561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [07:54<04:03, 14.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 94.32% recall = 98.31%\n",
      "Test :Total accu = 82.58% recall = 87.40%\n",
      "==================================================\n",
      "Epoch = 33\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.23628964\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.01471566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [08:08<03:48, 14.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 94.40% recall = 98.33%\n",
      "Test :Total accu = 83.24% recall = 87.24%\n",
      "==================================================\n",
      "Epoch = 34\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.23502508\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.02425628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [08:22<03:34, 14.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 94.43% recall = 98.36%\n",
      "Test :Total accu = 83.37% recall = 86.88%\n",
      "==================================================\n",
      "Epoch = 35\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.23397048\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.03035467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [08:37<03:20, 14.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 94.53% recall = 98.45%\n",
      "Test :Total accu = 83.34% recall = 87.24%\n",
      "==================================================\n",
      "Epoch = 36\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.23261768\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.02608568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [08:51<03:06, 14.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 94.50% recall = 98.40%\n",
      "Test :Total accu = 83.69% recall = 86.61%\n",
      "==================================================\n",
      "Epoch = 37\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.23222153\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.02450330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [09:06<02:52, 14.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 94.58% recall = 98.36%\n",
      "Test :Total accu = 83.12% recall = 87.79%\n",
      "==================================================\n",
      "Epoch = 38\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.23077605\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.02290576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [09:20<02:38, 14.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 94.55% recall = 98.38%\n",
      "Test :Total accu = 83.43% recall = 87.09%\n",
      "==================================================\n",
      "Epoch = 39\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.22956086\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.02087555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [09:35<02:24, 14.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 94.60% recall = 98.47%\n",
      "Test :Total accu = 83.58% recall = 86.91%\n",
      "==================================================\n",
      "Epoch = 40\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.22827564\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.02821747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [09:49<02:08, 14.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 94.69% recall = 98.45%\n",
      "Test :Total accu = 83.23% recall = 87.45%\n",
      "==================================================\n",
      "Epoch = 41\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.22680441\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.03493674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [10:03<01:54, 14.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 94.62% recall = 98.43%\n",
      "Test :Total accu = 83.50% recall = 87.10%\n",
      "==================================================\n",
      "Epoch = 42\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.22666198\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.02474518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [10:18<01:40, 14.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 94.60% recall = 98.41%\n",
      "Test :Total accu = 83.53% recall = 86.90%\n",
      "==================================================\n",
      "Epoch = 43\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.22559338\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.02921211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [10:32<01:26, 14.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 94.63% recall = 98.41%\n",
      "Test :Total accu = 83.54% recall = 87.03%\n",
      "==================================================\n",
      "Epoch = 44\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.22520625\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.02518640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [10:46<01:11, 14.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 94.69% recall = 98.43%\n",
      "Test :Total accu = 83.30% recall = 87.46%\n",
      "==================================================\n",
      "Epoch = 45\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.22203133\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.02706055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [11:01<00:57, 14.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 94.69% recall = 98.54%\n",
      "Test :Total accu = 83.53% recall = 87.08%\n",
      "==================================================\n",
      "Epoch = 46\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.22351809\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.02710268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [11:15<00:43, 14.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 94.72% recall = 98.47%\n",
      "Test :Total accu = 83.41% recall = 87.14%\n",
      "==================================================\n",
      "Epoch = 47\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.22167528\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.03393611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [11:29<00:28, 14.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 94.74% recall = 98.45%\n",
      "Test :Total accu = 83.34% recall = 87.36%\n",
      "==================================================\n",
      "Epoch = 48\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.22260550\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.03732993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [11:43<00:14, 14.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 94.70% recall = 98.49%\n",
      "Test :Total accu = 83.47% recall = 87.20%\n",
      "==================================================\n",
      "Epoch = 49\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.22193933\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.02778368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [11:58<00:00, 14.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 94.74% recall = 98.46%\n",
      "Test :Total accu = 83.58% recall = 87.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "F1_test_max, F1_test_curr = 0, 0\n",
    "\n",
    "for epoch in tqdm(range(50)):\n",
    "    print('='*50)\n",
    "    print('Epoch = {}'.format(epoch))\n",
    "    print('='*50)\n",
    "    batch_loss_list, logits_list, y_list, y_len_list = train_eval_single_epoch(model_lstm, \n",
    "                                                                               dataset_conll2003_train_loader, \n",
    "                                                                               optimizer=optimizer,\n",
    "                                                                               loss_fn=loss_fn,\n",
    "                                                                               is_train=True)\n",
    "    scheduler.step() # 加上后好一些\n",
    "    print('training loss = {:.8f}'.format(sum(batch_loss_list)/len(batch_loss_list)))\n",
    "    test_batch_loss_list, test_logits_list, test_y_list, test_y_len_list = func_eval(model_lstm, \n",
    "                                                                               dataset_conll2003_test_loader, \n",
    "                                                                               loss_fn=loss_fn)\n",
    "    print('testing loss = {:.8f}'.format(sum(test_batch_loss_list)/len(test_batch_loss_list)))\n",
    "    \n",
    "    # 评估\n",
    "    train_dict = func_cal_accu_recall(logits_list=logits_list, y_list=y_list, y_len_list=y_len_list)\n",
    "    test_dict = func_cal_accu_recall(logits_list=test_logits_list, y_list=test_y_list, y_len_list=test_y_len_list)\n",
    "    \n",
    "    print('Train :Total accu = {:.2f}% recall = {:.2f}%'.format(\n",
    "            (train_dict['tp'] + train_dict['tn'])/train_dict['n_total']*100, \n",
    "            train_dict['tp']/(train_dict['tp'] + train_dict['fn'])*100))\n",
    "    \n",
    "    print('Test :Total accu = {:.2f}% recall = {:.2f}%'.format(\n",
    "            (test_dict['tp'] + test_dict['tn'])/test_dict['n_total']*100, \n",
    "            test_dict['tp']/(test_dict['tp'] + test_dict['fn'])*100))\n",
    "    \n",
    "    # save model if current f1 rate is better than previous ones \n",
    "    accu_test = (test_dict['tp'] + test_dict['tn'])/test_dict['n_total']\n",
    "    recall_test = test_dict['tp']/(test_dict['tp'] + test_dict['fn'])\n",
    "    F1_test_curr = 1/(1/accu_test+1/recall_test)\n",
    "    if F1_test_curr>F1_test_max:\n",
    "        torch.save(model_lstm.state_dict(), './models/model_v1_'+model_name+'epoch='+str(epoch)+\n",
    "                   'accu='+str(round(accu_test,4))+\n",
    "                   'recall='+str(round(recall_test,4))+\n",
    "                   'F1='+str(round(F1_test_curr,4)))\n",
    "    F1_test_max = max(F1_test_curr, F1_test_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Epoch = 50\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.22028840\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.03339294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  from ipykernel import kernelapp as app\n",
      "  5%|▌         | 1/20 [00:14<04:39, 14.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 94.76% recall = 98.45%\n",
      "Test :Total accu = 83.41% recall = 87.19%\n",
      "==================================================\n",
      "Epoch = 51\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.21958178\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.04335617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:29<04:22, 14.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 94.73% recall = 98.49%\n",
      "Test :Total accu = 83.55% recall = 86.95%\n",
      "==================================================\n",
      "Epoch = 52\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.21985352\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.03043874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:43<04:07, 14.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 94.71% recall = 98.51%\n",
      "Test :Total accu = 83.43% recall = 87.15%\n",
      "==================================================\n",
      "Epoch = 53\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.22113321\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.03107773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:58<03:51, 14.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 94.71% recall = 98.52%\n",
      "Test :Total accu = 83.60% recall = 86.88%\n",
      "==================================================\n",
      "Epoch = 54\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.22038740\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.03071490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [01:12<03:36, 14.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 94.79% recall = 98.48%\n",
      "Test :Total accu = 83.50% recall = 86.95%\n",
      "==================================================\n",
      "Epoch = 55\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.22095717\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.03156417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [01:26<03:20, 14.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 94.80% recall = 98.50%\n",
      "Test :Total accu = 83.45% recall = 87.14%\n",
      "==================================================\n",
      "Epoch = 56\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.22138221\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.03338755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [01:41<03:06, 14.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 94.77% recall = 98.43%\n",
      "Test :Total accu = 83.43% recall = 87.24%\n",
      "==================================================\n",
      "Epoch = 57\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.21964724\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.02886947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [01:55<02:53, 14.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 94.78% recall = 98.46%\n",
      "Test :Total accu = 83.53% recall = 87.05%\n",
      "==================================================\n",
      "Epoch = 58\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.21924993\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.03327863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [02:10<02:39, 14.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 94.80% recall = 98.50%\n",
      "Test :Total accu = 83.53% recall = 87.01%\n",
      "==================================================\n",
      "Epoch = 59\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.22017605\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.02911192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [02:25<02:25, 14.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 94.80% recall = 98.49%\n",
      "Test :Total accu = 83.46% recall = 87.16%\n",
      "==================================================\n",
      "Epoch = 60\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.21954502\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.03007094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [02:39<02:11, 14.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 94.77% recall = 98.49%\n",
      "Test :Total accu = 83.48% recall = 87.09%\n",
      "==================================================\n",
      "Epoch = 61\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.21803828\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.03711423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [02:54<01:56, 14.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 94.75% recall = 98.45%\n",
      "Test :Total accu = 83.49% recall = 87.20%\n",
      "==================================================\n",
      "Epoch = 62\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.21870519\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.02511061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [03:08<01:41, 14.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 94.80% recall = 98.52%\n",
      "Test :Total accu = 83.50% recall = 87.09%\n",
      "==================================================\n",
      "Epoch = 63\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.21957169\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.02933003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [03:22<01:26, 14.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 94.83% recall = 98.53%\n",
      "Test :Total accu = 83.50% recall = 87.03%\n",
      "==================================================\n",
      "Epoch = 64\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.21881127\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.03341302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [03:37<01:12, 14.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 94.81% recall = 98.50%\n",
      "Test :Total accu = 83.50% recall = 87.02%\n",
      "==================================================\n",
      "Epoch = 65\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.21914673\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.03151531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [03:52<00:58, 14.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 94.79% recall = 98.46%\n",
      "Test :Total accu = 83.45% recall = 87.11%\n",
      "==================================================\n",
      "Epoch = 66\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.21696893\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.03725075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [04:06<00:43, 14.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 94.83% recall = 98.52%\n",
      "Test :Total accu = 83.52% recall = 87.06%\n",
      "==================================================\n",
      "Epoch = 67\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.21733979\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.03242237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [04:21<00:29, 14.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 94.87% recall = 98.45%\n",
      "Test :Total accu = 83.46% recall = 87.13%\n",
      "==================================================\n",
      "Epoch = 68\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.21888341\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.03608008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [04:36<00:14, 14.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 94.74% recall = 98.51%\n",
      "Test :Total accu = 83.48% recall = 87.07%\n",
      "==================================================\n",
      "Epoch = 69\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.21793188\n",
      "Total (training) batch = 108\n",
      "testing loss = 1.02967578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [04:50<00:00, 14.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :Total accu = 94.86% recall = 98.47%\n",
      "Test :Total accu = 83.49% recall = 87.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(50,70)):\n",
    "    print('='*50)\n",
    "    print('Epoch = {}'.format(epoch))\n",
    "    print('='*50)\n",
    "    batch_loss_list, logits_list, y_list, y_len_list = train_eval_single_epoch(model_lstm, \n",
    "                                                                               dataset_conll2003_train_loader, \n",
    "                                                                               optimizer=optimizer,\n",
    "                                                                               loss_fn=loss_fn,\n",
    "                                                                               is_train=True)\n",
    "    scheduler.step() # 加上后好一些\n",
    "    print('training loss = {:.8f}'.format(sum(batch_loss_list)/len(batch_loss_list)))\n",
    "    test_batch_loss_list, test_logits_list, test_y_list, test_y_len_list = func_eval(model_lstm, \n",
    "                                                                               dataset_conll2003_test_loader, \n",
    "                                                                               loss_fn=loss_fn)\n",
    "    print('testing loss = {:.8f}'.format(sum(test_batch_loss_list)/len(test_batch_loss_list)))\n",
    "    \n",
    "    # 评估\n",
    "    train_dict = func_cal_accu_recall(logits_list=logits_list, y_list=y_list, y_len_list=y_len_list)\n",
    "    test_dict = func_cal_accu_recall(logits_list=test_logits_list, y_list=test_y_list, y_len_list=test_y_len_list)\n",
    "    \n",
    "    print('Train :Total accu = {:.2f}% recall = {:.2f}%'.format(\n",
    "            (train_dict['tp'] + train_dict['tn'])/train_dict['n_total']*100, \n",
    "            train_dict['tp']/(train_dict['tp'] + train_dict['fn'])*100))\n",
    "    \n",
    "    print('Test :Total accu = {:.2f}% recall = {:.2f}%'.format(\n",
    "            (test_dict['tp'] + test_dict['tn'])/test_dict['n_total']*100, \n",
    "            test_dict['tp']/(test_dict['tp'] + test_dict['fn'])*100))\n",
    "    \n",
    "    # save model if current f1 rate is better than previous ones \n",
    "    accu_test = (test_dict['tp'] + test_dict['tn'])/test_dict['n_total']\n",
    "    recall_test = test_dict['tp']/(test_dict['tp'] + test_dict['fn'])\n",
    "    F1_test_curr = 1/(1/accu_test+1/recall_test)\n",
    "    if F1_test_curr>F1_test_max:\n",
    "        torch.save(model_lstm.state_dict(), './models/model_v1_'+model_name+'epoch='+str(epoch)+\n",
    "                   'accu='+str(round(accu_test,4))+\n",
    "                   'recall='+str(round(recall_test,4))+\n",
    "                   'F1='+str(round(F1_test_curr,4)))\n",
    "    F1_test_max = max(F1_test_curr, F1_test_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练总结\n",
    "\n",
    "能发现验证集在 21 epoch 时已达到最好状态，之后train开始过拟合，eval 也没办法继续提升准确率。\n",
    "\n",
    "=====V0=====\n",
    "\n",
    "epoch=0\n",
    "- Train :Total accu = 68.88% recall = 73.88%\n",
    "- Test :Total accu = 66.67% recall = 73.10%\n",
    "\n",
    "epoch=10\n",
    "- Train :Total accu = 88.65% recall = 95.18%\n",
    "- Test :Total accu = 79.97% recall = 86.82%\n",
    "\n",
    "epoch=21\n",
    "- Train :Total accu = 94.92% recall = 98.48%\n",
    "- Test :Total accu = 83.26% recall = 90.43%\n",
    "\n",
    "epoch=50\n",
    "- Train :Total accu = 96.36% recall = 99.08%\n",
    "- Test :Total accu = 83.81% recall = 90.54%\n",
    "\n",
    "=====V1====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
