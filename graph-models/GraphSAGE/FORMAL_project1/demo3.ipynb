{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "b17af66f-8846-4f6f-94f9-4ffd5da5b8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 该版确保id的输入正确\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "import scipy.sparse as sp\n",
    "import dgl\n",
    "import torch\n",
    "from dgl.data import AsNodePredDataset#, AsLinkPredDataset\n",
    "import numpy as np \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from dgl.nn import SAGEConv\n",
    "import dgl.function as fn\n",
    "import tqdm\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0b1b7f6f-f5f3-4799-931d-79c203022b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda cpu\n"
     ]
    }
   ],
   "source": [
    "gpu_device = torch.device('cuda')\n",
    "cpu_device = torch.device('cpu')\n",
    "print(gpu_device, cpu_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21cf481a-ec47-4dbc-8e77-913b36e3c1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cora(data_path):\n",
    "    data0 = dgl.data.CSVDataset(data_path,force_reload=True)\n",
    "    data = AsNodePredDataset(data0, split_ratio=(0.5,0.2,0.3))\n",
    "    g = data[0]\n",
    "    g.ndata[\"features\"] = g.ndata.pop(\"feat\").float()\n",
    "    g.ndata[\"labels\"] = g.ndata.pop(\"label\")\n",
    "    return g, data.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51c1b149-634e-42be-a92e-a5c8f22f1ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done saving data into cached files.\n"
     ]
    }
   ],
   "source": [
    "data_path = '../../dataset/cora_csv_idrank/'\n",
    "raw_g, n_classes = load_cora(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cea11152-e199-4741-8825-4d5a65742487",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = dgl.add_reverse_edges(raw_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c1e36a97-6a7f-4ed6-8627-faac8d7197d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 7\n"
     ]
    }
   ],
   "source": [
    "node_features = g.ndata['features']\n",
    "node_labels = g.ndata['labels']\n",
    "num_features = node_features.shape[1]\n",
    "num_classes = (node_labels.max() + 1).item()\n",
    "print('Number of classes: {:d}'.format(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da87adf8-cbe1-4db7-b1e0-4ac298c2a1f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([   0,    0,    0,  ..., 2586, 1874, 2707]),\n",
       "  tensor([  21,  905,  906,  ..., 1874, 1876, 1897])),\n",
       " '  ',\n",
       " torch.Size([10858]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.edges(), '  ', g.edges()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d9ad53f-8c07-4866-b133-f79d3d7acfec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0,    1,    2,  ..., 2705, 2706, 2707])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "279325e9-3375-4821-86a9-ca8bec560f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  21,  905,  906,  ..., 2586, 1874, 2707]),\n",
       " tensor([  21,  905,  906,  ..., 2586, 1874, 2707]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.edges()[1][:10858//2], g.edges()[0][10858//2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c64e30-d140-4987-8f34-b6da43cd762e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "35c3964e-24b0-480a-ba4b-c2d2775e6903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5429, 5430, 5431,  ..., 5426, 5427, 5428])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reverse id 的规定\n",
    "\"\"\"\n",
    "reverse_eids (Tensor or dict[etype, Tensor], optional) –\n",
    "A tensor of reverse edge ID mapping. The i-th element indicates the ID of the i-th edge’s reverse edge.\n",
    "\"\"\"\n",
    "E = g.number_of_edges()\n",
    "reverse_eids = torch.cat([torch.arange(E//2,  E), torch.arange(0, E//2)])\n",
    "reverse_eids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a1587e82-5737-48bb-97b5-9e2142544ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 规定提取的边\n",
    "eids = np.arange(g.number_of_edges())\n",
    "eids = np.random.permutation(eids)\n",
    "\n",
    "train_size = int(0.7 * len(eids))\n",
    "train_eid = eids[:train_size]\n",
    "# train_g = dgl.remove_edges(g, eids[train_size:])\n",
    "\n",
    "test_eid = eids[train_size:]\n",
    "# test_g = dgl.remove_edges(g, eids[:train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "96852bdd-3c50-49cd-b8a6-e103d9982af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7600,), (3258,))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_eid.shape, test_eid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bb9d56-bd4c-4691-8703-a70859a36e34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "313b880d-ab82-430b-ad19-93d95b95d064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立样本迭代器-base\n",
    "# https://docs.dgl.ai/generated/dgl.dataloading.DataLoader.html\n",
    "# https://docs.dgl.ai/en/0.8.x/generated/dgl.dataloading.as_edge_prediction_sampler.html#dgl.dataloading.as_edge_prediction_sampler\n",
    "\n",
    "negative_sampler = dgl.dataloading.negative_sampler.Uniform(3)  # N = 3\n",
    "neighbor_sampler = dgl.dataloading.MultiLayerNeighborSampler([10,5])\n",
    "edge_sampler = dgl.dataloading.as_edge_prediction_sampler(\n",
    "    sampler=neighbor_sampler,\n",
    "    negative_sampler=negative_sampler\n",
    ")\n",
    "edge_sampler_excl = dgl.dataloading.as_edge_prediction_sampler(\n",
    "    sampler=neighbor_sampler,\n",
    "    negative_sampler=negative_sampler,\n",
    "    exclude='reverse_id',\n",
    "    reverse_eids=reverse_eids\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "7d3cf7c5-0428-495e-8b14-cdf7ac9d6620",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = dgl.dataloading.DataLoader(\n",
    "    graph = g, \n",
    "    indices = train_eid, # indices=torch.arange(g.number_of_edges()), \n",
    "    graph_sampler=edge_sampler_excl,\n",
    "    batch_size=512,\n",
    "    shuffle=True,\n",
    "    drop_last=False,\n",
    "    num_workers=4,\n",
    "    device='cpu'\n",
    "    # use_prefetch_thread=True,\n",
    "    # pin_prefetcher=True, \n",
    "    # use_ddp=True       # Make it work with distributed data parallel\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "77053e19-2c15-44e8-8d6a-fa58ae305fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = dgl.dataloading.DataLoader(\n",
    "    graph=g,\n",
    "    indices = test_eid, #indices=torch.arange(g.number_of_edges()),\n",
    "    graph_sampler=edge_sampler,\n",
    "    batch_size=512,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=4,\n",
    "    device='cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "4e7775d5-6776-49ed-a52d-071ddebe4785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input nodes: 2624\n",
      "Positive graph # nodes: 1625 # edges: 512\n",
      "Negative graph # nodes: 1625 # edges: 1536\n",
      "[Block(num_src_nodes=2624, num_dst_nodes=2432, num_edges=8331), Block(num_src_nodes=2432, num_dst_nodes=1625, num_edges=4576)]\n"
     ]
    }
   ],
   "source": [
    "input_nodes, pos_graph, neg_graph, mfgs = next(iter(train_dataloader))\n",
    "print('Number of input nodes:', len(input_nodes))\n",
    "print('Positive graph # nodes:', pos_graph.number_of_nodes(), '# edges:', pos_graph.number_of_edges())\n",
    "print('Negative graph # nodes:', neg_graph.number_of_nodes(), '# edges:', neg_graph.number_of_edges())\n",
    "print(mfgs)\n",
    "\n",
    "# 128 * 3 = 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "fc89158d-f2df-4104-8c8b-bc6cd5e3f9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input nodes: 2634\n",
      "Positive graph # nodes: 1644 # edges: 512\n",
      "Negative graph # nodes: 1644 # edges: 1536\n",
      "[Block(num_src_nodes=2634, num_dst_nodes=2449, num_edges=9262), Block(num_src_nodes=2449, num_dst_nodes=1644, num_edges=5402)]\n"
     ]
    }
   ],
   "source": [
    "input_nodes, pos_graph, neg_graph, mfgs = next(iter(test_dataloader))\n",
    "print('Number of input nodes:', len(input_nodes))\n",
    "print('Positive graph # nodes:', pos_graph.number_of_nodes(), '# edges:', pos_graph.number_of_edges())\n",
    "print('Negative graph # nodes:', neg_graph.number_of_nodes(), '# edges:', neg_graph.number_of_edges())\n",
    "print(mfgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "c709b3d9-39e2-4f08-b254-28c89887c616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 制定model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats):\n",
    "        super(Model, self).__init__()\n",
    "        self.h_feats = h_feats\n",
    "        self.in_feats = in_feats\n",
    "        self.conv1 = SAGEConv(self.in_feats, self.h_feats, aggregator_type='mean')\n",
    "        self.conv2 = SAGEConv(self.h_feats, self.h_feats, aggregator_type='mean')\n",
    "        \n",
    "    def forward(self, mfgs, x):\n",
    "        h_dst = x[: mfgs[0].num_dst_nodes()]\n",
    "        h = self.conv1(mfgs[0], (x, h_dst))\n",
    "        h = F.relu(h)\n",
    "        h_dst = h[: mfgs[1].num_dst_nodes()]\n",
    "        h = self.conv2(mfgs[1], (h, h_dst))\n",
    "        return h\n",
    "    \n",
    "\n",
    "class DotPredictor(nn.Module):\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            g.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n",
    "            # return g.edata['score'][:,0]\n",
    "            return torch.sigmoid(g.edata['score'][:,0]) # 相比原版接了sigmoid缩放到0、1区间\n",
    "        \n",
    "\n",
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, h_feats):\n",
    "        super().__init__()\n",
    "        self.W1 = nn.Linear(h_feats * 2, h_feats)\n",
    "        self.W2 = nn.Linear(h_feats, 1)\n",
    "\n",
    "    def apply_edges_method(self, edges):\n",
    "        \"\"\"\n",
    "        Computes a scalar score for each edge of the given graph.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        edges :\n",
    "            Has three members ``src``, ``dst`` and ``data``, each of\n",
    "            which is a dictionary representing the features of the\n",
    "            source nodes, the destination nodes, and the edges\n",
    "            themselves.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            A dictionary of new edge features.\n",
    "        \"\"\"\n",
    "        h = torch.cat([edges.src['h'], edges.dst['h']], 1)\n",
    "        return {'score': self.W2(F.relu(self.W1(h))).squeeze(1)}\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            g.apply_edges(self.apply_edges_method)\n",
    "            return g.edata['score'][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "07f94b14-71a9-430c-a83d-0c3fa44bf567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评估模块\n",
    "def compute_auc(pos_score, neg_score):\n",
    "    with torch.no_grad():\n",
    "        scores = torch.cat([pos_score, neg_score]).numpy()\n",
    "        labels = torch.cat([torch.ones_like(pos_score), torch.zeros_like(neg_score)])\n",
    "        return roc_auc_score(labels, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "16f05601-088f-429c-a6e1-60f415e984e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_result(model, predictor, test_dataloader, threds):\n",
    "    model.eval()\n",
    "    with torch.no_grad(), test_dataloader.enable_cpu_affinity():\n",
    "        pred_all, pred01_all, label_all = torch.Tensor(), torch.Tensor(), torch.Tensor()\n",
    "        loss_all = 0\n",
    "        for step, (input_nodes, pos_graph, neg_graph, mfgs) in enumerate(test_dataloader):\n",
    "            pos_graph = pos_graph.to(gpu_device)\n",
    "            neg_graph = neg_graph.to(gpu_device)\n",
    "            mfgs = [mfg.int().to(gpu_device) for mfg in mfgs]\n",
    "\n",
    "            inputs = mfgs[0].srcdata['features']\n",
    "            outputs = model(mfgs, inputs)\n",
    "            pos_score = predictor(pos_graph, outputs)\n",
    "            neg_score = predictor(neg_graph, outputs)\n",
    "\n",
    "            # the score and label of edges (real and non-existent)\n",
    "            score = torch.cat([pos_score, neg_score])\n",
    "            label = torch.cat([torch.ones_like(pos_score), torch.zeros_like(neg_score)])\n",
    "            loss = F.binary_cross_entropy_with_logits(score, label)\n",
    "\n",
    "            pred = score.cpu()\n",
    "            pred01 = pred.detach()\n",
    "            pred01[pred01>=threds] = 1\n",
    "            pred01[pred01<threds] = 0\n",
    "            \n",
    "            pred_all = torch.cat([pred_all, pred])\n",
    "            pred01_all = torch.cat([pred01_all, pred01])\n",
    "            label_all = torch.cat([label_all, label.cpu()])\n",
    "            loss_all += loss\n",
    "            \n",
    "        accu = sklearn.metrics.accuracy_score(label_all.cpu().numpy(),pred01_all)\n",
    "        auc = roc_auc_score(label_all.cpu().numpy(), pred_all)\n",
    "        size = len(test_dataloader)\n",
    "            # tq.set_postfix({'test-loss': '%.03f' % loss.item(), \n",
    "            #                 'test-accu': '%0.3f'%accu.item(),\n",
    "            #                 'test-auc': '%0.3f'%auc.item()\n",
    "            #                }, refresh=False)\n",
    "    return accu, auc, pred_all, pred01_all, label_all, loss_all, size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "181a4de9-17b4-4b5c-88ba-da6ca26778ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化\n",
    "model = Model(num_features, 256).to(gpu_device)\n",
    "predictor = DotPredictor().to(gpu_device)\n",
    "opt = torch.optim.Adam(list(model.parameters()) + list(predictor.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "6c28b982-258b-4036-9d99-8794b7a4235b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 DL workers are assigned to cpus [0, 1, 2, 3], main process will use cpus [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:08<00:00,  1.72it/s, train:=-----, loss=0.847, accu=0.559, auc=0.820]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 DL workers are assigned to cpus [0, 1, 2, 3], main process will use cpus [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:09<00:00,  1.63it/s, train:=-----, loss=0.823, accu=0.627, auc=0.890]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 DL workers are assigned to cpus [0, 1, 2, 3], main process will use cpus [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:08<00:00,  1.70it/s, train:=-----, loss=0.815, accu=0.648, auc=0.905]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 DL workers are assigned to cpus [0, 1, 2, 3], main process will use cpus [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ 执行测试集 ------------ :\n",
      "test_loss=0.807, test_accu=0.665, test_auc=0.773\n",
      "4 DL workers are assigned to cpus [0, 1, 2, 3], main process will use cpus [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:08<00:00,  1.78it/s, train:=-----, loss=0.797, accu=0.691, auc=0.918]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 DL workers are assigned to cpus [0, 1, 2, 3], main process will use cpus [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:08<00:00,  1.76it/s, train:=-----, loss=0.775, accu=0.719, auc=0.910]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 DL workers are assigned to cpus [0, 1, 2, 3], main process will use cpus [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:09<00:00,  1.61it/s, train:=-----, loss=0.759, accu=0.739, auc=0.903]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 DL workers are assigned to cpus [0, 1, 2, 3], main process will use cpus [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ 执行测试集 ------------ :\n",
      "test_loss=0.750, test_accu=0.758, test_auc=0.837\n",
      "4 DL workers are assigned to cpus [0, 1, 2, 3], main process will use cpus [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:08<00:00,  1.67it/s, train:=-----, loss=0.735, accu=0.784, auc=0.900]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 DL workers are assigned to cpus [0, 1, 2, 3], main process will use cpus [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:08<00:00,  1.81it/s, train:=-----, loss=0.734, accu=0.783, auc=0.891]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 DL workers are assigned to cpus [0, 1, 2, 3], main process will use cpus [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:05<00:00,  2.74it/s, train:=-----, loss=0.716, accu=0.815, auc=0.887]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 DL workers are assigned to cpus [0, 1, 2, 3], main process will use cpus [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ 执行测试集 ------------ :\n",
      "test_loss=0.722, test_accu=0.802, test_auc=0.864\n",
      "4 DL workers are assigned to cpus [0, 1, 2, 3], main process will use cpus [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:08<00:00,  1.69it/s, train:=-----, loss=0.718, accu=0.806, auc=0.884]\n"
     ]
    }
   ],
   "source": [
    "# 训练过程\n",
    "best_test_auc = 0\n",
    "best_model_path = './../demo1/models/'\n",
    "\n",
    "\n",
    "for epoch in range(10):\n",
    "    with train_dataloader.enable_cpu_affinity(), tqdm.tqdm(train_dataloader) as tq:\n",
    "        # with tqdm.tqdm(train_dataloader) as tq:\n",
    "        for step, (input_nodes, pos_graph, neg_graph, mfgs) in enumerate(tq):\n",
    "            model.train()\n",
    "            pos_graph = pos_graph.to(gpu_device)\n",
    "            neg_graph = neg_graph.to(gpu_device)\n",
    "            mfgs = [mfg.int().to(gpu_device) for mfg in mfgs]\n",
    "\n",
    "            inputs = mfgs[0].srcdata['features']\n",
    "            outputs = model(mfgs, inputs)\n",
    "            pos_score = predictor(pos_graph, outputs)\n",
    "            neg_score = predictor(neg_graph, outputs)\n",
    "\n",
    "            # the score and label of edges (real and non-existent)\n",
    "            score = torch.cat([pos_score, neg_score])\n",
    "            label = torch.cat([torch.ones_like(pos_score), torch.zeros_like(neg_score)])\n",
    "            loss = F.binary_cross_entropy_with_logits(score, label)\n",
    "\n",
    "            pred = score.cpu()\n",
    "            pred01 = pred.detach()\n",
    "            threds = 0.5\n",
    "            pred01[pred01>=threds] = 1\n",
    "            pred01[pred01<threds] = 0\n",
    "            with torch.no_grad():\n",
    "                accu = sklearn.metrics.accuracy_score(label.cpu().numpy(),pred01)\n",
    "                auc = roc_auc_score(label.cpu().numpy(), score.detach().cpu())\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "                \n",
    "            tq.set_postfix({\n",
    "                'train:':'-----',\n",
    "                'loss': '%.03f' % loss.item(), \n",
    "                'accu': '%0.3f'%accu.item(),\n",
    "                'auc': '%0.3f'%auc.item()\n",
    "                           }, refresh=False)\n",
    "            LOG_FORMAT = \"%(asctime)s - %(levelname)s - %(message)s\"\n",
    "            DATE_FORMAT = \"%m/%d/%Y %H:%M:%S %p\"\n",
    "\n",
    "            logging.basicConfig(filename='my.log', level=logging.INFO, format=LOG_FORMAT, datefmt=DATE_FORMAT)\n",
    "            logging.info(epoch,loss,accu,auc)\n",
    "        \n",
    "        # train里的 每 N 个step执行一次\n",
    "        if (epoch+1)%3==0:\n",
    "            test_accu, test_auc, test_pred_all, test_pred01_all, test_label_all, test_loss_all, test_size = get_test_result(\n",
    "                model, predictor, test_dataloader, threds)\n",
    "            print(\"------------ 执行测试集 ------------ :\")\n",
    "            print(\"test_loss={:.3f}, test_accu={:.3f}, test_auc={:.3f}\".format(test_loss_all/test_size, test_accu, test_auc))\n",
    "            if(best_test_auc < test_auc):\n",
    "                best_test_auc = test_auc\n",
    "                # model save\n",
    "                torch.save({'state':model.state_dict(), 'optimizer':opt.state_dict(), 'epoch':epoch, 'size':len(train_dataloader)}, \n",
    "                          os.path.join(\"./models/model-demo3\"+\"batch_size=\"+str(len(train_dataloader))+\"epoch=\"+str(epoch)+\".pt\"))\n",
    "\n",
    "            # https://docs.dgl.ai/en/0.8.x/tutorials/blitz/4_link_predict.html 最终test预测到 auc=0.865 程度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "45b79a1e-abd5-4eb1-b2b5-9cce42d0f4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "LOG_FORMAT = \"%(asctime)s - %(levelname)s - %(message)s\"\n",
    "DATE_FORMAT = \"%m/%d/%Y %H:%M:%S %p\"\n",
    "\n",
    "logging.basicConfig(filename='my.log', level=logging.DEBUG, format=LOG_FORMAT, datefmt=DATE_FORMAT)\n",
    "logging.info('aaa',exc_info=True, stack_info=True,extra={'epoch':str(epoch)})#,loss,accu,auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "3bc73219-be25-4341-8051-e12c9870ccd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logger(filename, verbosity=1, name=None):\n",
    "    level_dict = {0: logging.DEBUG, 1: logging.INFO, 2: logging.WARNING}\n",
    "    formatter = logging.Formatter(\n",
    "        \"[%(asctime)s][%(filename)s][line:%(lineno)d][%(levelname)s] %(message)s\"\n",
    "    )\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(level_dict[verbosity])\n",
    "\n",
    "    # Output to file\n",
    "    fh = logging.FileHandler(filename, \"w\")\n",
    "    fh.setFormatter(formatter)\n",
    "    logger.addHandler(fh)\n",
    "\n",
    "    # Output to terminal\n",
    "    sh = logging.StreamHandler()\n",
    "    sh.setFormatter(formatter)\n",
    "    logger.addHandler(sh)\n",
    "\n",
    "    return logger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "ad75e607-4b69-4e26-9147-1b831bccdbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-03-08 20:10:22,335][1856998988.py][line:3][INFO] start training!\n",
      "[2023-03-08 20:10:22,350][1856998988.py][line:4][INFO] Epoch:[9/10]\t loss=0.71763\t acc=0.806\n",
      "[2023-03-08 20:10:22,351][1856998988.py][line:5][INFO] finish training!\n"
     ]
    }
   ],
   "source": [
    "logger = get_logger('./demo3-train.log')\n",
    "\n",
    "logger.info('start training!')\n",
    "logger.info('Epoch:[{}/{}]\\t loss={:.5f}\\t acc={:.3f}'.format(epoch, 10, loss, accu))\n",
    "logger.info('finish training!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d576ca51-4618-4636-8358-702eab62e132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "7d33ee69-cda9-46b7-806b-45ecf8c3281b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 实例化\n",
    "model1 = Model(num_features, 256).to(gpu_device)\n",
    "predictor1 = DotPredictor().to(gpu_device)\n",
    "opt1 = torch.optim.Adam(list(model.parameters()) + list(predictor.parameters()))\n",
    "\n",
    "model1.load_state_dict(torch.load(\"./models/model-demo3epoch=8.pt\")['state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "949f37c9-d38e-499a-be4c-327bc1307e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 DL workers are assigned to cpus [0, 1, 2, 3], main process will use cpus [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "------------ 执行测试集 ------------ :\n",
      "test_loss=0.721, test_accu=0.802, test_auc=0.863\n"
     ]
    }
   ],
   "source": [
    "test_accu, test_auc, test_pred_all, test_pred01_all, test_label_all, test_loss_all, test_size = get_test_result(\n",
    "    model1, predictor, test_dataloader, threds)\n",
    "print(\"------------ 执行测试集 ------------ :\")\n",
    "print(\"test_loss={:.3f}, test_accu={:.3f}, test_auc={:.3f}\".format(test_loss_all/test_size, test_accu, test_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b68a0a-27c0-4bef-9914-3c8d5b1b0b0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "311a542c-c318-44a2-bbbb-194f7b256aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推断 emb 模块\n",
    "def inference(model, graph, infer_device, num_workers=4):\n",
    "    with torch.no_grad():\n",
    "        nodes = torch.arange(graph.number_of_nodes())\n",
    "        # 保持跟上方一致。但也可以全采样，参考：https://docs.dgl.ai/guide/minibatch-inference.html\n",
    "        sampler = dgl.dataloading.MultiLayerNeighborSampler([10,5]) \n",
    "        # dgl.dataloading.NodeDataLoader 在 0.8 以上版本已 depreciate\n",
    "        train_dataloader = dgl.dataloading.DataLoader(\n",
    "            graph=graph,\n",
    "            indices=torch.arange(graph.number_of_nodes()),\n",
    "            graph_sampler=sampler,\n",
    "            batch_size=1024,\n",
    "            shuffle=False,\n",
    "            drop_last=False,\n",
    "            num_workers=num_workers,\n",
    "            device='cpu'\n",
    "        )\n",
    "        with train_dataloader.enable_cpu_affinity():\n",
    "            result = []\n",
    "            for input_nodes, output_nodes, mfgs in train_dataloader:\n",
    "                mfgs = [mfg.int().to(infer_device) for mfg in mfgs]\n",
    "                inputs = mfgs[0].srcdata['features']\n",
    "                result.append(model(mfgs, inputs))\n",
    "                mfgs = [mfg.int().to('cpu') for mfg in mfgs]\n",
    "        return torch.cat(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "62bb400c-9f97-4fb9-baf0-2ca36c58f9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.eval()\n",
    "model1 = model1.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "573c161f-1827-4cc7-ba92-cc608b691578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 DL workers are assigned to cpus [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], main process will use cpus [30, 31]\n",
      "CPU times: user 191 ms, sys: 1.89 s, total: 2.08 s\n",
      "Wall time: 6.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "emb = inference(model1, graph=g, infer_device=gpu_device, num_workers=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "bfc33c6b-a633-4e08-aba8-5e9293a392c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 DL workers are assigned to cpus [0, 1, 2, 3], main process will use cpus [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "CPU times: user 892 ms, sys: 388 ms, total: 1.28 s\n",
      "Wall time: 2.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "emb = inference(model1, graph=g, infer_device=gpu_device, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "f1a4e642-a35e-4f42-9a97-fb2c29e102ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 DL workers are assigned to cpus [0, 1, 2, 3, 4, 5, 6, 7], main process will use cpus [8, 9, 10, 11, 12, 13, 14, 15]\n",
      "CPU times: user 703 ms, sys: 664 ms, total: 1.37 s\n",
      "Wall time: 3.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "emb = inference(model1, graph=g, infer_device=gpu_device, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "852f0247-1653-4517-a13d-d3b5414b0724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.333"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(0.33333,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6416a8-f80b-472c-ab45-b2b268a6ef66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
