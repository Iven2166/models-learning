{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as torch\n",
    "import dgl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, v = th.tensor([0,0,0,1]), th.tensor([1,2,3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = dgl.graph((u,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=4, num_edges=4,\n",
      "      ndata_schemes={}\n",
      "      edata_schemes={})\n",
      "nodes:  tensor([0, 1, 2, 3])\n",
      "edges:  (tensor([0, 0, 0, 1]), tensor([1, 2, 3, 3]))\n"
     ]
    }
   ],
   "source": [
    "print(g)\n",
    "print('nodes: ', g.nodes())\n",
    "print('edges: ', g.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demo.py          dgl-demo.ipynb   dgl_graphsage.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tmp/Documents/python_envs/dgl_envs/lib/python3.7/site-packages/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
      "  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'\n"
     ]
    }
   ],
   "source": [
    "node_fea = pd.read_table('../../cora/cora.content', header=None)\n",
    "edges = pd.read_table('../../cora/cora.cites', header=None)\n",
    "# 0是node id， 1434是node label\n",
    "node_fea.rename(columns={0: 'node_id', 1434: 'label'}, inplace=True)\n",
    "\n",
    "node_id_number_dict = dict(zip(node_fea['node_id'].unique(),\n",
    "                               range(node_fea['node_id'].nunique())))\n",
    "node_fea['node_id_number'] = node_fea['node_id'].map(node_id_number_dict)\n",
    "edges['edge1'] = edges[0].map(node_id_number_dict)\n",
    "edges['edge2'] = edges[1].map(node_id_number_dict)\n",
    "\n",
    "label_dict = dict(zip(node_fea['label'].unique(),\n",
    "                      range(node_fea['label'].nunique())))\n",
    "node_fea['label_number'] = node_fea['label'].map(label_dict)\n",
    "\n",
    "src = np.array(edges['edge1'].values)\n",
    "dst = np.array(edges['edge2'].values)\n",
    "\n",
    "u = np.concatenate([src, dst])\n",
    "v = np.concatenate([dst, src])\n",
    "\n",
    "my_net = dgl.DGLGraph((u, v))\n",
    "\n",
    "fea_id = range(1, 1434)\n",
    "tensor_fea = torch.tensor(node_fea[fea_id].values, dtype=torch.float32)\n",
    "\n",
    "fea_np = nn.Embedding(2708, 1433)\n",
    "fea_np.weight = nn.Parameter(tensor_fea)\n",
    "\n",
    "my_net.ndata['features'] = fea_np.weight\n",
    "my_net.ndata['label'] = torch.tensor(node_fea['label_number'].values)\n",
    "\n",
    "in_feats = 1433\n",
    "n_classes = node_fea['label'].nunique()\n",
    "\n",
    "data = in_feats, n_classes, my_net, fea_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "pandas.core.frame.DataFrame"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(node_fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_node_ids = np.array(node_fea.groupby('label_number').apply(lambda x: x.sort_values('node_id_number')['node_id_number'].values[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "val_node_ids = np.array(node_fea.groupby('label_number')\n",
    "                        .apply(lambda x: x.sort_values('node_id_number')['node_id_number'].values[21:110]))\n",
    "test_node_ids = np.array(node_fea.groupby('label_number')\n",
    "                         .apply(lambda x: x.sort_values('node_id_number')['node_id_number'].values[111:300]))\n",
    "\n",
    "train_nid = []\n",
    "val_nid = []\n",
    "test_nid = []\n",
    "for (train_nodes, val_nodes, test_nodes) in zip(train_node_ids, val_node_ids, test_node_ids):\n",
    "    train_nid.extend(train_nodes)\n",
    "    val_nid.extend(val_nodes)\n",
    "    test_nid.extend(test_nodes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "140"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_nid)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "train_mask = node_fea['node_id_number'].apply(lambda x: x in train_nid)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "0        True\n1        True\n2        True\n3        True\n4        True\n        ...  \n2703    False\n2704    False\n2705    False\n2706    False\n2707    False\nName: node_id_number, Length: 2708, dtype: bool"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mask"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "def load_subtensor(nfeat, labels, seeds, input_nodes, device):\n",
    "    \"\"\"\n",
    "    extracts features and labels for a subset of nodes\n",
    "    \"\"\"\n",
    "    batch_inputs = nfeat[input_nodes].to(device)\n",
    "    batch_labels = labels[seeds].to(device)\n",
    "    return batch_inputs, batch_labels\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "# data\n",
    "in_feats, n_classes, my_net, fea_para = data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "hidden_size = 16\n",
    "n_layers = 2\n",
    "sample_size = [10, 25]\n",
    "activation = F.relu\n",
    "dropout = 0.5\n",
    "aggregator = 'mean'\n",
    "batch_s = 128\n",
    "num_workers = 0\n",
    "learning_rate = 0.003\n",
    "device_num = 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "n_feat = my_net.ndata['features']\n",
    "labels = my_net.ndata['label']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([2708, 1433]), torch.Size([2708]))"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_feat.shape, labels.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "from dgl.nn.pytorch import SAGEConv\n",
    "\n",
    "device = 'cpu'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "class MyGraphSAGE(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_feats,\n",
    "                 n_hidden,\n",
    "                 n_classes,\n",
    "                 n_layers,\n",
    "                 activation,\n",
    "                 dropout,\n",
    "                 aggregator):\n",
    "        \"\"\"\n",
    "        in_feats: 输入的特征数量\n",
    "        n_hidden: 内部的隐藏层的维度\n",
    "        n_classes: 分类数目\n",
    "        n_layers: 层数\n",
    "        activation: 激活函数\n",
    "        dropout: dropout比例\n",
    "        aggregator: 聚合方法 Aggregator type to use (mean, gcn, pool, lstm)\n",
    "        \"\"\"\n",
    "        super(MyGraphSAGE, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_classes = n_classes\n",
    "        self.layer = nn.ModuleList()  # layer 是一连串的处理手段\n",
    "\n",
    "        # SAGEConv: https://docs.dgl.ai/en/0.8.x/generated/dgl.nn.pytorch.conv.SAGEConv.html\n",
    "        # 第一层是输入的特征，映射到隐藏层\n",
    "        self.layer.append(SAGEConv(in_feats, n_hidden, aggregator))\n",
    "        # 第二到倒数第二层，输入和输出都是 隐藏层的维度\n",
    "        for i in range(1, n_layers - 1):\n",
    "            self.layer.append(SAGEConv(n_hidden, n_hidden, aggregator))\n",
    "        # 最后一层，是隐藏层到类别的映射\n",
    "        self.layer.append(SAGEConv(n_hidden, n_classes, aggregator))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, blocks, feats):\n",
    "        \"\"\"\n",
    "        前向计算函数\n",
    "        blocks: 待理解\n",
    "        feats: 最初的特征输入\n",
    "        layer: 是SAGEConv的每一层，block和h都是其输入特征\n",
    "        \"\"\"\n",
    "        h = feats  # 应该是最初始输入的节点特征\n",
    "        for i, (layer, block) in enumerate(zip(self.layer, blocks)):\n",
    "            h = layer(block, h)\n",
    "            if i != self.n_layers - 1:\n",
    "                h = self.activation(h)\n",
    "                h = self.dropout(h)\n",
    "        return h\n",
    "\n",
    "    def inference(self, my_net, val_nid, batch_s, num_worker, device):\n",
    "        \"\"\"\n",
    "        my_net:\n",
    "        val_nid:\n",
    "        batch_s:\n",
    "        \"\"\"\n",
    "        # 采样类\n",
    "        sampler = dgl.dataloading.MultiLayerFullNeighborSampler(self.n_layers)\n",
    "        dataloader = dgl.dataloading.NodeDataLoader(\n",
    "            my_net,\n",
    "            val_nid,\n",
    "            sampler,\n",
    "            batch_size=batch_s,\n",
    "            shuffle=True,\n",
    "            drop_last=False,\n",
    "            num_workers=num_worker\n",
    "        )\n",
    "        # 最后返回结果： 节点数，节点类别\n",
    "        ret = torch.zeros(my_net.num_nodes(), self.n_classes)\n",
    "\n",
    "        # 推理计算过程\n",
    "        # dataloader 返回 输入节点，输出节点，blocks\n",
    "        for input_nodes, output_nodes, blocks in dataloader:\n",
    "            h = blocks[0].srcdata['feature'].to(device)\n",
    "            for i, (layer, block) in enumerate(zip(self.layer, blocks)):\n",
    "                block = block.int().to(device)\n",
    "                h = layer(block, h)\n",
    "                if i != self.n_layers - 1:\n",
    "                    h = self.activation(h)\n",
    "                    h = self.dropout(h)\n",
    "            ret[output_nodes] = h.cpu()\n",
    "        return ret"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "CrossEntropyLoss()"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample_size = [5,10,15]\n",
    "sample_size = [10, 25]\n",
    "sampler = dgl.dataloading.MultiLayerNeighborSampler(sample_size)\n",
    "dataloader = dgl.dataloading.NodeDataLoader(\n",
    "    my_net,\n",
    "    train_nid,\n",
    "    sampler,\n",
    "    batch_size=batch_s,\n",
    "    shuffle=True,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "model = MyGraphSAGE(in_feats,\n",
    "                    hidden_size,\n",
    "                    n_classes,\n",
    "                    n_layers,\n",
    "                    activation,\n",
    "                    dropout,\n",
    "                    aggregator)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "model.train()\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn.to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tmp/Documents/python_envs/dgl_envs/lib/python3.7/site-packages/dgl/dataloading/dataloader.py:859: DGLWarning: Dataloader CPU affinity opt is not enabled, consider switching it on (see enable_cpu_affinity() or CPU best practices for DGL [https://docs.dgl.ai/tutorials/cpu/cpu_best_practises.html])\n",
      "  dgl_warning(f'Dataloader CPU affinity opt is not enabled, consider switching it on '\n"
     ]
    }
   ],
   "source": [
    "for batch, (input_nodes, output_nodes, block) in enumerate(dataloader):\n",
    "    if batch == 0:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "batch_feature, batch_label = load_subtensor(n_feat, labels, output_nodes, input_nodes, device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1332, 1433])"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_feature.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "data": {
      "text/plain": "[Block(num_src_nodes=1332, num_dst_nodes=573, num_edges=2764),\n Block(num_src_nodes=573, num_dst_nodes=128, num_edges=650)]"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([1332]), torch.Size([128]))"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_nodes.shape, output_nodes.shape, batch_label.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "block = [block_.int().to(device) for block_ in block]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "data": {
      "text/plain": "[Block(num_src_nodes=1332, num_dst_nodes=573, num_edges=2764),\n Block(num_src_nodes=573, num_dst_nodes=128, num_edges=650)]"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "model_pred = model(block, batch_feature)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([128, 7]),\n tensor([-0.1425,  0.2223,  0.0846, -0.7226, -0.5764, -0.7439, -0.5485],\n        grad_fn=<SelectBackward0>))"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pred.shape, model_pred[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0., 0., 0.,  ..., 1., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 1., 0.,  ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.]], grad_fn=<IndexSelectBackward0>)"
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block[0].srcdata['features'].shape"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
