
note4: dependency-parsing

note5: LM-RNN-LSTM

note6: NMT(neural machine translation) seq2seq, attention

assignment: http://web.stanford.edu/class/cs224n/assignments/a4.pdf

note7 / lecture 9: transformers

http://web.stanford.edu/class/cs224n/slides/cs224n-2022-lecture09-transformers.pdf

note8 / lecture 10: pretraining

http://web.stanford.edu/class/cs224n/slides/cs224n-2022-lecture10-pretraining.pdf