{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "from dgl.data import AsNodePredDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cora():\n",
    "    data0 = dgl.data.CSVDataset('../graph_dgl/cora_csv/')\n",
    "    data = AsNodePredDataset(data0, split_ratio=(0.5,0.2,0.3))\n",
    "    g = data[0]\n",
    "    g.ndata[\"features\"] = g.ndata.pop(\"feat\")\n",
    "    g.ndata[\"labels\"] = g.ndata.pop(\"label\")\n",
    "    return g, data.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def load_reddit(self_loop=True, raw_dir='~/.dgl/'):\n",
    "    from dgl.data import RedditDataset\n",
    "\n",
    "    # load reddit data\n",
    "    data = RedditDataset(self_loop=self_loop, raw_dir=raw_dir)\n",
    "    g = data[0]\n",
    "    g.ndata[\"features\"] = g.ndata.pop(\"feat\")\n",
    "    g.ndata[\"labels\"] = g.ndata.pop(\"label\")\n",
    "    return g, data.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading data from cached files.\n"
     ]
    }
   ],
   "source": [
    "g, n_classes = load_cora()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_edges = g.num_edges()\n",
    "reverse_eids = torch.cat([\n",
    "    torch.arange(n_edges // 2, n_edges),\n",
    "    torch.arange(0, n_edges // 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5429"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2714, 2715, 2716,  ..., 2711, 2712, 2713])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_eids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nid = th.nonzero(g.ndata['train_mask'], as_tuple=True)[0]\n",
    "val_nid = th.nonzero(g.ndata['val_mask'], as_tuple=True)[0]\n",
    "test_nid = th.nonzero(~(g.ndata['train_mask'] | g.ndata['val_mask']), as_tuple=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inductive_split(g):\n",
    "    \"\"\"Split the graph into training graph, validation graph, and test graph by training\n",
    "    and validation masks.  Suitable for inductive models.\"\"\"\n",
    "    train_g = g.subgraph(g.ndata[\"train_mask\"])\n",
    "    val_g = g.subgraph(g.ndata[\"train_mask\"] | g.ndata[\"val_mask\"])\n",
    "    test_g = g\n",
    "    return train_g, val_g, test_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fan_out=[10, 25]\n",
    "sampler = dgl.dataloading.MultiLayerNeighborSampler([int(_) for _ in fan_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dgl.dataloading.neighbor_sampler.NeighborSampler at 0x7f957e8c64d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train_mask', 'val_mask', 'test_mask', 'features', 'labels'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.ndata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method formats in module dgl.heterograph:\n",
      "\n",
      "formats(formats=None) method of dgl.heterograph.DGLHeteroGraph instance\n",
      "    Get a cloned graph with the specified sparse format(s) or query\n",
      "    for the usage status of sparse formats\n",
      "    \n",
      "    The API copies both the graph structure and the features.\n",
      "    \n",
      "    If the input graph has multiple edge types, they will have the same\n",
      "    sparse format.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    formats : str or list of str or None\n",
      "    \n",
      "        * If formats is None, return the usage status of sparse formats\n",
      "        * Otherwise, it can be ``'coo'``/``'csr'``/``'csc'`` or a sublist of\n",
      "          them, specifying the sparse formats to use.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    dict or DGLGraph\n",
      "    \n",
      "        * If formats is None, the result will be a dict recording the usage\n",
      "          status of sparse formats.\n",
      "        * Otherwise, a DGLGraph will be returned, which is a clone of the\n",
      "          original graph with the specified sparse format(s) ``formats``.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    \n",
      "    The following example uses PyTorch backend.\n",
      "    \n",
      "    >>> import dgl\n",
      "    >>> import torch\n",
      "    \n",
      "    **Homographs or Heterographs with A Single Edge Type**\n",
      "    \n",
      "    >>> g = dgl.graph(([0, 0, 1], [2, 3, 2]))\n",
      "    >>> g.ndata['h'] = torch.ones(4, 1)\n",
      "    >>> # Check status of format usage\n",
      "    >>> g.formats()\n",
      "    {'created': ['coo'], 'not created': ['csr', 'csc']}\n",
      "    >>> # Get a clone of the graph with 'csr' format\n",
      "    >>> csr_g = g.formats('csr')\n",
      "    >>> # Only allowed formats will be displayed in the status query\n",
      "    >>> csr_g.formats()\n",
      "    {'created': ['csr'], 'not created': []}\n",
      "    >>> # Features are copied as well\n",
      "    >>> csr_g.ndata['h']\n",
      "    tensor([[1.],\n",
      "            [1.],\n",
      "            [1.],\n",
      "            [1.]])\n",
      "    \n",
      "    **Heterographs with Multiple Edge Types**\n",
      "    \n",
      "    >>> g = dgl.heterograph({\n",
      "    ...     ('user', 'plays', 'game'): (torch.tensor([0, 1, 1, 2]),\n",
      "    ...                                 torch.tensor([0, 0, 1, 1])),\n",
      "    ...     ('developer', 'develops', 'game'): (torch.tensor([0, 1]),\n",
      "    ...                                         torch.tensor([0, 1]))\n",
      "    ...     })\n",
      "    >>> g.formats()\n",
      "    {'created': ['coo'], 'not created': ['csr', 'csc']}\n",
      "    >>> # Get a clone of the graph with 'csr' format\n",
      "    >>> csr_g = g.formats('csr')\n",
      "    >>> # Only allowed formats will be displayed in the status query\n",
      "    >>> csr_g.formats()\n",
      "    {'created': ['csr'], 'not created': []}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(g.formats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. nagetive sampler"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
