{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51292383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267af309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf59973",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010cf1a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac31d723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "# specify GPU\n",
    "device = torch.device(\"cuda\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5835a554",
   "metadata": {},
   "source": [
    "# 下载数据 fetch the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e8b1bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (C:\\Users\\iven2\\.cache\\huggingface\\datasets\\imdb\\plain_text\\1.0.0\\2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5915009072246edbca6d2e15d454e95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "imdb = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d134ee6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': (25000, 2), 'test': (25000, 2), 'unsupervised': (50000, 2)}\n",
      "dict_keys(['text', 'label']) dict_keys(['text', 'label'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-1, -1]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(imdb.shape)\n",
    "print(imdb['train'][0].keys(), imdb['unsupervised'][0].keys())\n",
    "imdb['unsupervised'][0:2]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f57c786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 2) 25000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I would put this at the top of my list of film...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Whoever wrote the screenplay for this movie ob...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>When I first saw a glimpse of this movie, I qu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Who are these \"They\"- the actors? the filmmake...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This is said to be a personal film for Peter B...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I rented I AM CURIOUS-YELLOW from my video sto...      0\n",
       "1  \"I Am Curious: Yellow\" is a risible and preten...      0\n",
       "2  If only to avoid making this type of film in t...      0\n",
       "3  This film was probably inspired by Godard's Ma...      0\n",
       "4  Oh, brother...after hearing about this ridicul...      0\n",
       "5  I would put this at the top of my list of film...      0\n",
       "6  Whoever wrote the screenplay for this movie ob...      0\n",
       "7  When I first saw a glimpse of this movie, I qu...      0\n",
       "8  Who are these \"They\"- the actors? the filmmake...      0\n",
       "9  This is said to be a personal film for Peter B...      0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turn the data into csv files\n",
    "\n",
    "df = pd.concat([pd.DataFrame.from_dict(imdb['train']),\n",
    "                pd.DataFrame.from_dict(imdb['test'])], axis=0)\n",
    "print(df.shape, df.label.sum())\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef916aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2514\n"
     ]
    }
   ],
   "source": [
    "df = df.sample(5000)\n",
    "print(df.label.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ee3e3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train dataset into train, validation and test sets\n",
    "train_text, temp_text, train_labels, temp_labels = train_test_split(df['text'], df['label'], \n",
    "                                                                    random_state=2166, \n",
    "                                                                    test_size=0.3, \n",
    "                                                                    stratify=df['label'])\n",
    "\n",
    "\n",
    "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
    "                                                                random_state=2166, \n",
    "                                                                test_size=0.5, \n",
    "                                                                stratify=temp_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "750e2645",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# import bert-based pretrained model\n",
    "\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f427a0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreTrainedTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n"
     ]
    }
   ],
   "source": [
    "# vocab_size=30522, model_max_len=512\n",
    "print(tokenizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e17c4897",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[101, 2023, 2003, 1037, 3653, 23654, 2098, 2944, 1998, 2057, 2224, 2009, 2085, 102], [101, 2040, 2024, 1057, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0], [101, 100, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 100, 1740, 1743, 1746, 1861, 102, 0, 0, 0, 0, 0, 0, 0]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]]}\n"
     ]
    }
   ],
   "source": [
    "try_text = [\n",
    "    'this is a pretrained model and we use it now',\n",
    "    'who are u?',\n",
    "    '[UNK]',\n",
    "    '试一下中文'\n",
    "]\n",
    "try_text_id = tokenizer.batch_encode_plus(try_text, padding = True)\n",
    "print(try_text_id)\n",
    "\n",
    "# integers 101, 102, ... are special tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "0bd51a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[216, 62, 106, 167, 76, 430, 441, 361, 182, 481, 487, 164, 124, 77, 147, 154, 157, 773, 134, 285]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAPpklEQVR4nO3db2xdd33H8fd3DS2jZknaTlaVRHMZ1aSq1Vhq0U4g5NAN+mdaOglQpW6kLFKeFFpWkGrgATyZFiaNqkgTUkaQwoQwrIAaURh0bS3Eg2YkXWn6Z6VuCRArtCuEQGAMun334P5SO8aOfe1rO/fr90uy7jm/3zn3/s5X9358/LvnXkdmIkmq5bdWewCSpN4z3CWpIMNdkgoy3CWpIMNdkgpat9oDALjoootyaGioq31+/vOfc/755y/PgPqMtTid9ZhiLaZUrMWhQ4dezMzfna3vrAj3oaEhDh482NU+4+PjjIyMLM+A+oy1OJ31mGItplSsRUR8b64+p2UkqSDDXZIKMtwlqSDDXZIKMtwlqSDDXZIKMtwlqSDDXZIKMtwlqaCz4hOqK2lo9L45+47svmEFRyJJy8czd0kqyHCXpIIMd0kqyHCXpIIMd0kqyHCXpIIMd0kqyHCXpIIMd0kqyHCXpIIMd0kqyHCXpIIMd0kqyHCXpIIMd0kqyHCXpIIMd0kqyHCXpIIMd0kqyHCXpIIMd0kqaEHhHhF/ExFPRMTjEfHZiHhlRFwSEQciYiIiPhcR57Ztz2vrE61/aFmPQJL0G+YN94jYBNwGDGfm5cA5wE3AR4G7MvO1wHFgZ9tlJ3C8td/VtpMkraCFTsusA347ItYBrwKOAW8G7mn9+4Ab2/L2tk7rvyYioiejlSQtSGTm/BtF3A78LfDfwNeB24GH29k5EbEF+GpmXh4RjwPXZubR1vcscFVmvjjjPncBuwAGBwevHBsb62rgJ0+eZGBgoKt9AA5Pnpiz74pN67u+v7PBYmtRlfWYYi2mVKzFtm3bDmXm8Gx96+bbOSI20jkbvwT4CfAvwLVLHVRm7gH2AAwPD+fIyEhX+4+Pj9PtPgC3jN43Z9+Rm7u/v7PBYmtRlfWYYi2mrLVaLGRa5k+A72bmf2Xmr4EvAm8ANrRpGoDNwGRbngS2ALT+9cCPejpqSdIZLSTcvw9cHRGvanPn1wBPAg8Bb2vb7ADubcv72zqt/8FcyNyPJKln5g33zDxA543RR4DDbZ89wJ3AHRExAVwI7G277AUubO13AKPLMG5J0hnMO+cOkJkfBj48o/k54PWzbPtL4O1LH5okabH8hKokFWS4S1JBhrskFWS4S1JBhrskFWS4S1JBhrskFWS4S1JBhrskFWS4S1JBhrskFWS4S1JBhrskFWS4S1JBhrskFWS4S1JBhrskFWS4S1JBhrskFWS4S1JBhrskFWS4S1JBhrskFWS4S1JBhrskFWS4S1JBhrskFWS4S1JBhrskFWS4S1JBhrskFWS4S1JBhrskFWS4S1JBhrskFWS4S1JBCwr3iNgQEfdExH9GxFMR8ccRcUFE3B8Rz7TbjW3biIiPR8RERDwWEVuX9xAkSTOtW+B2dwP/mplvi4hzgVcBHwQeyMzdETEKjAJ3AtcBl7afq4BPtNuz3tDofbO2H9l9wwqPRJKWZt4z94hYD7wJ2AuQmb/KzJ8A24F9bbN9wI1teTvw6ex4GNgQERf3eNySpDOIzDzzBhGvA/YATwJ/CBwCbgcmM3ND2yaA45m5ISK+DOzOzG+2vgeAOzPz4Iz73QXsAhgcHLxybGysq4GfPHmSgYGBrvYBODx5out9rti0vut9VtJia1GV9ZhiLaZUrMW2bdsOZebwbH0LmZZZB2wF3pOZByLibjpTMC/LzIyIM/+WmCEz99D5pcHw8HCOjIx0szvj4+N0uw/ALXNMvZzJkZu7f5yVtNhaVGU9pliLKWutFgt5Q/UocDQzD7T1e+iE/fOnplva7QutfxLYMm3/za1NkrRC5g33zPwh8IOI+IPWdA2dKZr9wI7WtgO4ty3vB97Zrpq5GjiRmcd6O2xJ0pks9GqZ9wCfaVfKPAe8i84vhs9HxE7ge8A72rZfAa4HJoBftG0lSStoQeGemY8Cs03aXzPLtgncurRhSZKWwk+oSlJBhrskFWS4S1JBhrskFWS4S1JBhrskFWS4S1JBhrskFWS4S1JBhrskFWS4S1JBhrskFWS4S1JBhrskFWS4S1JBhrskFWS4S1JBhrskFWS4S1JBhrskFWS4S1JBhrskFWS4S1JBhrskFWS4S1JBhrskFWS4S1JBhrskFWS4S1JBhrskFWS4S1JBhrskFWS4S1JBhrskFWS4S1JBhrskFWS4S1JBCw73iDgnIv4jIr7c1i+JiAMRMRERn4uIc1v7eW19ovUPLdPYJUlz6ObM/XbgqWnrHwXuyszXAseBna19J3C8td/VtpMkraAFhXtEbAZuAD7Z1gN4M3BP22QfcGNb3t7Waf3XtO0lSSskMnP+jSLuAf4OeDXwfuAW4OF2dk5EbAG+mpmXR8TjwLWZebT1PQtclZkvzrjPXcAugMHBwSvHxsa6GvjJkycZGBjoah+Aw5Mnut7nik3ru95nJS22FlVZjynWYkrFWmzbtu1QZg7P1rduvp0j4s+AFzLzUESM9GpQmbkH2AMwPDycIyPd3fX4+Djd7gNwy+h9Xe9z5ObuH2clLbYWVVmPKdZiylqrxbzhDrwB+POIuB54JfA7wN3AhohYl5kvAZuBybb9JLAFOBoR64D1wI96PnJJ0pzmnXPPzA9k5ubMHAJuAh7MzJuBh4C3tc12APe25f1tndb/YC5k7keS1DNLuc79TuCOiJgALgT2tva9wIWt/Q5gdGlDlCR1ayHTMi/LzHFgvC0/B7x+lm1+Cby9B2OTJC2Sn1CVpIIMd0kqqKtpmX4ytIhLHiWpirLh3ktz/aI4svuGFR6JJC2M0zKSVJDhLkkFGe6SVJDhLkkFGe6SVJDhLkkFGe6SVJDhLkkFGe6SVJDhLkkFGe6SVJDhLkkFGe6SVJDhLkkFGe6SVJDhLkkFGe6SVJDhLkkFGe6SVJDhLkkFGe6SVJDhLkkFGe6SVJDhLkkFGe6SVJDhLkkFGe6SVNC61R5APxsavW/W9iO7b1jhkUjS6Txzl6SCDHdJKshwl6SCDHdJKmjecI+ILRHxUEQ8GRFPRMTtrf2CiLg/Ip5ptxtbe0TExyNiIiIei4ity30QkqTTLeTM/SXgfZl5GXA1cGtEXAaMAg9k5qXAA20d4Drg0vazC/hEz0ctSTqjecM9M49l5iNt+WfAU8AmYDuwr222D7ixLW8HPp0dDwMbIuLiXg9ckjS3yMyFbxwxBHwDuBz4fmZuaO0BHM/MDRHxZWB3Zn6z9T0A3JmZB2fc1y46Z/YMDg5eOTY21tXAT548ycDAwJz9hydPdHV/vXTFpvUr+njz1WKtsR5TrMWUirXYtm3bocwcnq1vwR9iiogB4AvAezPzp50878jMjIiF/5bo7LMH2AMwPDycIyMj3ezO+Pg4Z9rnljk+YLQSjtw8sqKPN18t1hrrMcVaTFlrtVjQ1TIR8Qo6wf6ZzPxia37+1HRLu32htU8CW6btvrm1SZJWyEKulglgL/BUZn5sWtd+YEdb3gHcO639ne2qmauBE5l5rIdjliTNYyHTMm8A/go4HBGPtrYPAruBz0fETuB7wDta31eA64EJ4BfAu3o54H7gd85IWm3zhnt7YzTm6L5mlu0TuHWJ45IkLYGfUJWkggx3SSrIcJekggx3SSqo7/8T01xXpkjSWuaZuyQVZLhLUkF9Py3TT/xwk6SV4pm7JBVkuEtSQYa7JBVkuEtSQYa7JBVkuEtSQYa7JBVkuEtSQX6I6Szgh5sk9Zpn7pJUkOEuSQUZ7pJUkOEuSQX5hupZzDdaJS2WZ+6SVJDhLkkFGe6SVJBz7n1o5lz8+654iVtG73MuXtLLDPdCfANW0ilOy0hSQZ65rwGe0Utrj2fuklSQ4S5JBRnuklSQc+6alfP0Un8z3NewuQJcUv9zWkaSCvLMXV1xukbqD4a7eqLbKZ5e/TKY7XHfd8VLjPTk3qX+tSzhHhHXAncD5wCfzMzdy/E46l/+BSAtr56He0ScA/wj8KfAUeBbEbE/M5/s9WOpHkNf6o3lOHN/PTCRmc8BRMQYsB0w3LVoXtkjdWc5wn0T8INp60eBq2ZuFBG7gF1t9WREPN3l41wEvLioERZzm7U4zW1w0W1/aT0anxtTKtbi9+bqWLU3VDNzD7BnsftHxMHMHO7hkPqWtTid9ZhiLaastVosx3Xuk8CWaeubW5skaYUsR7h/C7g0Ii6JiHOBm4D9y/A4kqQ59HxaJjNfioh3A1+jcynkpzLziV4/DkuY0inIWpzOekyxFlPWVC0iM1d7DJKkHvO7ZSSpIMNdkgrqy3CPiGsj4umImIiI0dUez0qIiCMRcTgiHo2Ig63tgoi4PyKeabcbW3tExMdbfR6LiK2rO/qliYhPRcQLEfH4tLaujz0idrTtn4mIHatxLEs1Ry0+EhGT7bnxaERcP63vA60WT0fEW6e19/1rKCK2RMRDEfFkRDwREbe39jX53PgNmdlXP3TepH0WeA1wLvBt4LLVHtcKHPcR4KIZbX8PjLblUeCjbfl64KtAAFcDB1Z7/Es89jcBW4HHF3vswAXAc+12Y1veuNrH1qNafAR4/yzbXtZeH+cBl7TXzTlVXkPAxcDWtvxq4DvtmNfkc2PmTz+eub/89QaZ+Svg1NcbrEXbgX1teR9w47T2T2fHw8CGiLh4FcbXE5n5DeDHM5q7Pfa3Avdn5o8z8zhwP3Dtsg++x+aoxVy2A2OZ+T+Z+V1ggs7rp8RrKDOPZeYjbflnwFN0PiG/Jp8bM/VjuM/29QabVmksKymBr0fEofbVDQCDmXmsLf8QGGzLa6FG3R579Zq8u001fOrUNARrqBYRMQT8EXAAnxtAf4b7WvXGzNwKXAfcGhFvmt6Znb8v1+R1rWv52JtPAL8PvA44BvzDqo5mhUXEAPAF4L2Z+dPpfWv5udGP4b4mv94gMyfb7QvAl+j8af38qemWdvtC23wt1KjbYy9bk8x8PjP/NzP/D/gnOs8NWAO1iIhX0An2z2TmF1uzzw36M9zX3NcbRMT5EfHqU8vAW4DH6Rz3qXf2dwD3tuX9wDvb1QFXAyem/ZlaRbfH/jXgLRGxsU1bvKW19b0Z76f8BZ3nBnRqcVNEnBcRlwCXAv9OkddQRASwF3gqMz82rcvnBvTf1TI59a73d+i84/+h1R7PChzva+hc0fBt4IlTxwxcCDwAPAP8G3BBaw86/zDlWeAwMLzax7DE4/8snemGX9OZD925mGMH/prOm4oTwLtW+7h6WIt/bsf6GJ0Au3ja9h9qtXgauG5ae9+/hoA30plyeQx4tP1cv1afGzN//PoBSSqoH6dlJEnzMNwlqSDDXZIKMtwlqSDDXZIKMtwlqSDDXZIK+n9yE661kHGpiAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compare the dataset text-length\n",
    "seq_len = [len(i.split()) for i in train_text]\n",
    "print(seq_len[0:20])\n",
    "pd.Series(seq_len).hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "40150fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "797 3500 0.2277142857142857\n"
     ]
    }
   ],
   "source": [
    "# because we have 80% of the lengths under 300, we may cut the max_length around 300?\n",
    "a = (pd.Series(seq_len)>300).sum()\n",
    "b = len(seq_len)\n",
    "print(a, b, a/b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e80487f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\APPS\\miniconda\\envs\\deep1\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2263: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "para_max_length = 300\n",
    "# tokenize and encode sequences in the training set\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text.tolist(),\n",
    "    max_length = para_max_length,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_text.tolist(),\n",
    "    max_length = para_max_length,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the test set\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_text.tolist(),\n",
    "    max_length = para_max_length,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "aaf8146a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.tokenization_utils_base.BatchEncoding"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokens_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83c28e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert lists to tensors\n",
    "\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.tolist())\n",
    "\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(val_labels.tolist())\n",
    "\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(test_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "a5a36b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create data loader with batches of data\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# for train\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "# for val \n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "val_sampler = RandomSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "ac5c42b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3500, 300])\n"
     ]
    }
   ],
   "source": [
    "print(train_data.tensors[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "a923b5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abd2fbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all the params\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e86140c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bert_withdense(nn.Module):\n",
    "    \n",
    "    def __init__(self, bert):\n",
    "        super(Bert_withdense, self).__init__()\n",
    "        \n",
    "        self.bert = bert\n",
    "        # dropout \n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        # relu activation function \n",
    "        self.relu = nn.ReLU()\n",
    "        # dense layer 1-2\n",
    "        self.dense1 = nn.Linear(768, 512)\n",
    "        self.dense2 = nn.Linear(512, 2)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    \n",
    "    def forward(self, sent_id, mask):\n",
    "#         _, cls_hs \n",
    "        bert_output = self.bert(sent_id, attention_mask = mask)\n",
    "        cls_hs = bert_output.pooler_output\n",
    "        x = self.dense1(cls_hs)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        # output layer\n",
    "        x = self.dense2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23ae84c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Bert_withdense(bert)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fcaf1a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bert_withdense(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (relu): ReLU()\n",
       "  (dense1): Linear(in_features=768, out_features=512, bias=True)\n",
       "  (dense2): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (softmax): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "82231136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer AdamW\n",
    "\n",
    "from transformers import AdamW\n",
    "optimizer = AdamW(model.parameters(), lr = 0.01) # learning rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "f7c11e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: [0.99658314 1.00344037]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "#compute the class weights\n",
    "class_weights = compute_class_weight(class_weight = 'balanced',\n",
    "                                     classes = np.unique(train_labels),\n",
    "                                     y = train_labels)\n",
    "\n",
    "print(\"Class Weights:\",class_weights) # a balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "a2d2a88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting list of class weights to a tensor\n",
    "weights= torch.tensor(class_weights,dtype=torch.float)\n",
    "\n",
    "# push to GPU\n",
    "weights = weights.to(device)\n",
    "\n",
    "# define the loss function \n",
    "# https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html\n",
    "# 'The negative log likelihood loss. \n",
    "# It is useful to train a classification problem with C classes.'\n",
    "cross_entropy  = nn.NLLLoss(weight=weights) \n",
    "\n",
    "# number of training epochs\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "e7b69c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "3c69b4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    total_preds = []\n",
    "    \n",
    "    # iterate over batches\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        \n",
    "        # progress update in every 50 batches\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            print('Batch {:>5,} of {:>5,}'.format(step, len(train_dataloader)))\n",
    "            \n",
    "        batch = [r.to(device) for r in batch]\n",
    "        sent_id, mask, labels = batch \n",
    "        \n",
    "        # clear the previously calculated gradients\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # prediction\n",
    "        preds = model(sent_id, mask)\n",
    "        \n",
    "        # compute the loss \n",
    "        loss = cross_entropy(preds, labels)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # backward pass to calculate the gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        # update the params\n",
    "        optimizer.step()\n",
    "        \n",
    "        preds = preds.detach().cpu().numpy()\n",
    "        total_preds.append(preds)\n",
    "        \n",
    "    # calculate the training loss of the epoch \n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    \n",
    "    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "    \n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "eca88919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to evaluate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "d0b2d87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    print(\"\\nEvaluating...\")\n",
    "    \n",
    "    # deactivate dropout layers\n",
    "    model.eval()\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    \n",
    "    # empty list to save the model predictions\n",
    "    total_preds = []\n",
    "    \n",
    "    # iterate over batches\n",
    "    for step,batch in enumerate(val_dataloader):\n",
    "        \n",
    "        # Progress update every 50 batches.\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
    "\n",
    "        # push the batch to gpu\n",
    "        batch = [t.to(device) for t in batch]\n",
    "\n",
    "        sent_id, mask, labels = batch\n",
    "\n",
    "        # deactivate autograd\n",
    "        with torch.no_grad():\n",
    "            # model predictions\n",
    "            preds = model(sent_id, mask)\n",
    "\n",
    "            # compute the validation loss between actual and predicted values\n",
    "            loss = cross_entropy(preds,labels)\n",
    "            total_loss = total_loss + loss.item()\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "            total_preds.append(preds)\n",
    "\n",
    "    # compute the validation loss of the epoch\n",
    "    avg_loss = total_loss / len(val_dataloader) \n",
    "    \n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "    \n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "98356210",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 5\n",
      "Batch    50 of   219\n",
      "Batch   100 of   219\n",
      "Batch   150 of   219\n",
      "Batch   200 of   219\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 1.106\n",
      "Validation Loss: 0.727\n",
      "\n",
      " Epoch 2 / 5\n",
      "Batch    50 of   219\n",
      "Batch   100 of   219\n",
      "Batch   150 of   219\n",
      "Batch   200 of   219\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.741\n",
      "Validation Loss: 0.735\n",
      "\n",
      " Epoch 3 / 5\n",
      "Batch    50 of   219\n",
      "Batch   100 of   219\n",
      "Batch   150 of   219\n",
      "Batch   200 of   219\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.665\n",
      "Validation Loss: 0.762\n",
      "\n",
      " Epoch 4 / 5\n",
      "Batch    50 of   219\n",
      "Batch   100 of   219\n",
      "Batch   150 of   219\n",
      "Batch   200 of   219\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.717\n",
      "Validation Loss: 1.140\n",
      "\n",
      " Epoch 5 / 5\n",
      "Batch    50 of   219\n",
      "Batch   100 of   219\n",
      "Batch   150 of   219\n",
      "Batch   200 of   219\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.845\n",
      "Validation Loss: 1.017\n"
     ]
    }
   ],
   "source": [
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "#for each epoch\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    #train model\n",
    "    train_loss, _ = train()\n",
    "    \n",
    "    #evaluate model\n",
    "    valid_loss, _ = evaluate()\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "d3e21b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 1            |        cudaMalloc retries: 2         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |    3169 MB |    3171 MB |   19468 GB |   19465 GB |\n",
      "|       from large pool |    3166 MB |    3166 MB |   19463 GB |   19460 GB |\n",
      "|       from small pool |       2 MB |       5 MB |       4 GB |       4 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |    3169 MB |    3171 MB |   19468 GB |   19465 GB |\n",
      "|       from large pool |    3166 MB |    3166 MB |   19463 GB |   19460 GB |\n",
      "|       from small pool |       2 MB |       5 MB |       4 GB |       4 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |    3312 MB |    3312 MB |    3858 MB |  559104 KB |\n",
      "|       from large pool |    3306 MB |    3306 MB |    3852 MB |  559104 KB |\n",
      "|       from small pool |       6 MB |       6 MB |       6 MB |       0 KB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |  146182 KB |  405859 KB |   12315 GB |   12315 GB |\n",
      "|       from large pool |  142848 KB |  403712 KB |   12310 GB |   12310 GB |\n",
      "|       from small pool |    3334 KB |    3334 KB |       5 GB |       5 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     283    |     480    |  748058    |  747775    |\n",
      "|       from large pool |      94    |     164    |  581811    |  581717    |\n",
      "|       from small pool |     189    |     316    |  166247    |  166058    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     283    |     480    |  748058    |  747775    |\n",
      "|       from large pool |      94    |     164    |  581811    |  581717    |\n",
      "|       from small pool |     189    |     316    |  166247    |  166058    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |      30    |      37    |      38    |       8    |\n",
      "|       from large pool |      27    |      34    |      35    |       8    |\n",
      "|       from small pool |       3    |       3    |       3    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      17    |      29    |  400353    |  400336    |\n",
      "|       from large pool |       9    |      25    |  342053    |  342044    |\n",
      "|       from small pool |       8    |       9    |   58300    |   58292    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bee9d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(torch.cuda, 'empty_cache'):\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8104809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method load_state_dict in module torch.nn.modules.module:\n",
      "\n",
      "load_state_dict(state_dict: 'OrderedDict[str, Tensor]', strict: bool = True) method of __main__.Bert_withdense instance\n",
      "    Copies parameters and buffers from :attr:`state_dict` into\n",
      "    this module and its descendants. If :attr:`strict` is ``True``, then\n",
      "    the keys of :attr:`state_dict` must exactly match the keys returned\n",
      "    by this module's :meth:`~torch.nn.Module.state_dict` function.\n",
      "    \n",
      "    Args:\n",
      "        state_dict (dict): a dict containing parameters and\n",
      "            persistent buffers.\n",
      "        strict (bool, optional): whether to strictly enforce that the keys\n",
      "            in :attr:`state_dict` match the keys returned by this module's\n",
      "            :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n",
      "    \n",
      "    Returns:\n",
      "        ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\n",
      "            * **missing_keys** is a list of str containing the missing keys\n",
      "            * **unexpected_keys** is a list of str containing the unexpected keys\n",
      "    \n",
      "    Note:\n",
      "        If a parameter or buffer is registered as ``None`` and its corresponding key\n",
      "        exists in :attr:`state_dict`, :meth:`load_state_dict` will raise a\n",
      "        ``RuntimeError``.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model.load_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d17f54e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load weights of best model\n",
    "path = 'saved_weights.pt'\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55507181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions for test data\n",
    "with torch.no_grad():\n",
    "    model.to('cuda')\n",
    "    preds = model(test_seq[0:100].to('cuda'), test_mask[0:100].to('cuda'))\n",
    "    preds = preds.detach().to('cpu').numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8faad220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.61      0.65        44\n",
      "           1       0.72      0.79      0.75        56\n",
      "\n",
      "    accuracy                           0.71       100\n",
      "   macro avg       0.71      0.70      0.70       100\n",
      "weighted avg       0.71      0.71      0.71       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# preds = np.argmax(preds, axis = 1)\n",
    "print(classification_report(test_y[0:100], preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a6294c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133dd16e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e02e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8f3f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc635aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2652d809",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68cfd26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "811e7ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = iter(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b4681d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = next(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "82a2dba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = [r.to(device) for r in t2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "3b99028c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_id, mask, labels = t2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "509be289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 300])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "26c6bef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t3 = bert(sent_id, attention_mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "bef8650a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state', 'pooler_output'])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeec32c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "07030195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__Python VERSION: 3.9.1 (default, Dec 11 2020, 09:29:25) [MSC v.1916 64 bit (AMD64)]\n",
      "__pyTorch VERSION: 1.11.0\n",
      "__CUDA VERSION\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Tue_May__3_19:00:59_Pacific_Daylight_Time_2022\n",
      "Cuda compilation tools, release 11.7, V11.7.64\n",
      "Build cuda_11.7.r11.7/compiler.31294372_0\n",
      "__CUDNN VERSION: 8200\n",
      "__Number CUDA Devices: 1\n",
      "__Devices\n",
      "Active CUDA Device: GPU 0\n",
      "Available devices  1\n",
      "Current cuda device  0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "print('__Python VERSION:', sys.version)\n",
    "print('__pyTorch VERSION:', torch.__version__)\n",
    "print('__CUDA VERSION')\n",
    "from subprocess import call\n",
    "# call([\"nvcc\", \"--version\"]) does not work\n",
    "! nvcc --version\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "print('__Devices')\n",
    "call([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=index,name,driver_version,memory.total,memory.used,memory.free\"])\n",
    "print('Active CUDA Device: GPU', torch.cuda.current_device())\n",
    "\n",
    "print ('Available devices ', torch.cuda.device_count())\n",
    "print ('Current cuda device ', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "ddace4df",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pycuda'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [230]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpycuda\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycuda\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compiler\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpycuda\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdriver\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdrv\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pycuda'"
     ]
    }
   ],
   "source": [
    "import pycuda\n",
    "from pycuda import compiler\n",
    "import pycuda.driver as drv\n",
    "\n",
    "drv.init()\n",
    "print(\"%d device(s) found.\" % drv.Device.count())\n",
    "           \n",
    "for ordinal in range(drv.Device.count()):\n",
    "    dev = drv.Device(ordinal)\n",
    "    print (ordinal, dev.name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d36652a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
