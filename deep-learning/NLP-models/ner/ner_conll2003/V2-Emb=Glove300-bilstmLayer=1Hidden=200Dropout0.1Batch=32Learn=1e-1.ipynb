{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "from tqdm import tqdm\n",
    "import sklearn\n",
    "\n",
    "# np/pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import torchtext\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "# transformer\n",
    "from datasets import load_dataset\n",
    "\n",
    "# CRF\n",
    "from torchcrf import CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import GloVe\n",
    "\n",
    "global_vectors = GloVe(name='840B', dim=300, cache='../../data/Glove840B300d/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 300])\n"
     ]
    }
   ],
   "source": [
    "print(global_vectors.get_vecs_by_tokens(['the','world','will','be','better']).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "Config = {\n",
    "    'num_tags':9,\n",
    "    'num_layers':1,\n",
    "    'embedding_dim':300,\n",
    "    'vocab_size':30289,\n",
    "    'hidden_dim':100,\n",
    "    'batch_size':32\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 探查conll2003数据\n",
    "\n",
    "定义dataset，dataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset conll2003 (/root/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d90e23949b344be58d33e4fc97ae6d98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data_udpos = torchtext.datasets.UDPOS(root='./torchtext_datasets_udpos/', split=('train','valid','test'))\n",
    "dataset_conll2003 = load_dataset(\"conll2003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0',\n",
       " 'tokens': ['SOCCER',\n",
       "  '-',\n",
       "  'JAPAN',\n",
       "  'GET',\n",
       "  'LUCKY',\n",
       "  'WIN',\n",
       "  ',',\n",
       "  'CHINA',\n",
       "  'IN',\n",
       "  'SURPRISE',\n",
       "  'DEFEAT',\n",
       "  '.'],\n",
       " 'pos_tags': [21, 8, 22, 37, 22, 22, 6, 22, 15, 12, 21, 7],\n",
       " 'chunk_tags': [11, 0, 11, 21, 11, 12, 0, 11, 13, 11, 12, 0],\n",
       " 'ner_tags': [0, 0, 5, 0, 0, 0, 0, 1, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_conll2003['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_tag2id = {'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7, 'I-MISC': 8}\n",
    "\n",
    "ner_id2tag = {}\n",
    "for key in ner_tag2id.keys():\n",
    "    ner_id2tag[ner_tag2id[key]] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-PER',\n",
       " 2: 'I-PER',\n",
       " 3: 'B-ORG',\n",
       " 4: 'I-ORG',\n",
       " 5: 'B-LOC',\n",
       " 6: 'I-LOC',\n",
       " 7: 'B-MISC',\n",
       " 8: 'I-MISC'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_id2tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O'],\n",
       " ['ORG', 'O', 'MISC', 'O', 'O', 'O', 'MISC', 'O', 'O'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ner_id_to_tags(ner_id_seq):\n",
    "    res1, res2 = [], []\n",
    "    for ner_id in ner_id_seq:\n",
    "        res1.append(ner_id2tag.get(ner_id, ''))\n",
    "        res2.append(ner_id2tag.get(ner_id, '-').split('-')[-1])\n",
    "    return res1, res2\n",
    "\n",
    "ner_id_to_tags(dataset_conll2003['train'][0]['ner_tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length = 124\n"
     ]
    }
   ],
   "source": [
    "m = 0\n",
    "for k in dataset_conll2003.keys():\n",
    "    for i in dataset_conll2003[k]['tokens']:\n",
    "        m = max(m, len(i))\n",
    "print('max length = {}'.format(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30289\n"
     ]
    }
   ],
   "source": [
    "word_to_ix = {}\n",
    "for k in dataset_conll2003.keys():\n",
    "    for tokens in dataset_conll2003[k]['tokens']:\n",
    "        for token in tokens:\n",
    "            if token not in word_to_ix:\n",
    "                word_to_ix[token] = len(word_to_ix)\n",
    "                \n",
    "Config['vocab_size'] = len(word_to_ix)\n",
    "\n",
    "print(Config['vocab_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_word2ix(word_to_ix, token_list):\n",
    "    res = list()\n",
    "    for token in token_list:\n",
    "        res.append(word_to_ix.get(token, len(word_to_ix)+1))\n",
    "    return {'token_ids':res}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98/cache-e993f22e7c8f1977.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98/cache-9da2d1c0e9528511.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98/cache-586edb6c12fcdba7.arrow\n"
     ]
    }
   ],
   "source": [
    "dataset_conll2003_train=dataset_conll2003['train'].map(lambda x: func_word2ix(word_to_ix, x['tokens']))\n",
    "dataset_conll2003_train.set_format(type=\"torch\", columns=['token_ids','ner_tags'])\n",
    "\n",
    "dataset_conll2003_test=dataset_conll2003['test'].map(lambda x: func_word2ix(word_to_ix, x['tokens']))\n",
    "dataset_conll2003_test.set_format(type=\"torch\", columns=['token_ids','ner_tags'])\n",
    "\n",
    "dataset_conll2003_val=dataset_conll2003['validation'].map(lambda x: func_word2ix(word_to_ix, x['tokens']))\n",
    "dataset_conll2003_val.set_format(type=\"torch\", columns=['token_ids','ner_tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.token_ids = self.data['token_ids'] # 在这变成torch.tensor，但长度不同\n",
    "        self.ner_tags = self.data['ner_tags']\n",
    "        self.tokens = self.data['tokens']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "#         curr = dict()\n",
    "#         curr['token_ids'] = self.token_ids\n",
    "#         curr['ner_tags'] = self.ner_tags\n",
    "        return self.token_ids[index], self.ner_tags[index], self.tokens[index]\n",
    "\n",
    "\n",
    "def collate_fn_padd(batch):\n",
    "    '''\n",
    "    Padds batch of variable length\n",
    "\n",
    "    note: it converts things ToTensor manually here since the ToTensor transform\n",
    "    assume it takes in images rather than arbitrary tensors.\n",
    "    '''\n",
    "    x, y, z = zip(*batch)\n",
    "    x_lens = [len(x_i) for x_i in x]\n",
    "    y_lens = [len(y_i) for y_i in y]\n",
    "    x_pad = torch.nn.utils.rnn.pad_sequence(x, batch_first=True)\n",
    "    y_pad = torch.nn.utils.rnn.pad_sequence(y, batch_first=True)\n",
    "    return x_pad, torch.tensor(x_lens), y_pad, torch.tensor(y_lens), z\n",
    "    \n",
    "dataset_conll2003_train_loader = DataLoader(\n",
    "    MyDataset(dataset_conll2003_train),\n",
    "    batch_size=32,\n",
    "    shuffle=True, \n",
    "    collate_fn=lambda x: collate_fn_padd(x))\n",
    "\n",
    "\n",
    "dataset_conll2003_test_loader = DataLoader(\n",
    "    MyDataset(dataset_conll2003_test),\n",
    "    batch_size=32,\n",
    "    shuffle=True, \n",
    "    collate_fn=lambda x: collate_fn_padd(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SEOUL', '1996-08-25']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataset_conll2003_train_loader))[4][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14041 3453\n"
     ]
    }
   ],
   "source": [
    "print(dataset_conll2003_train_loader.dataset.__len__(), dataset_conll2003_test_loader.dataset.__len__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## token-emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_weight = global_vectors.get_vecs_by_tokens(list(word_to_ix.keys()))\n",
    "embedding_glove = nn.Embedding.from_pretrained(glove_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1-glove_weight[0]==embedding_glove(torch.LongTensor([0]))).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLove_BiLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, config=None, embedding_weight = None):\n",
    "        super(GLove_BiLSTM, self).__init__()\n",
    "        self.config = config\n",
    "\n",
    "        # BiLSTM-model 给 emission 层定义参数\n",
    "        self.embedding_dim = self.config.get('embedding_dim', 300)\n",
    "        self.hidden_dim = self.config.get('hidden_dim', 200)\n",
    "        self.vocab_size = self.config.get('vocab_size', 30289)\n",
    "\n",
    "        if embedding_weight is not None:\n",
    "            self.word_embeds = nn.Embedding.from_pretrained(embedding_weight)\n",
    "        else:\n",
    "            self.word_embeds = nn.Embedding(self.vocab_size, self.embedding_dim)            \n",
    "            \n",
    "        self.target_size = self.config.get('num_tags', 9)\n",
    "        self.num_layers = self.config.get('num_layers',1)\n",
    "        self.batch_size = self.config.get('batch_size',16)\n",
    "        self.bidirectional = True\n",
    "\n",
    "        # lstm\n",
    "        self.lstm = nn.LSTM(input_size=self.embedding_dim, hidden_size=self.hidden_dim//2,\n",
    "                            num_layers=self.num_layers, bidirectional=self.bidirectional)\n",
    "        self.hidden2tag1 = nn.Linear(self.hidden_dim, self.target_size*3)\n",
    "        self.hidden2tag2 = nn.Linear(self.target_size*3, self.target_size)\n",
    "        self.dropout010 = nn.Dropout(0.1)\n",
    "        self.dropout020 = nn.Dropout(0.2)\n",
    "#         self.hidden_init = self.init_hidden()\n",
    "\n",
    "        # CRF-model\n",
    "        self.crf = CRF(self.config.get('num_tags', 9), batch_first=True)\n",
    "\n",
    "    def init_hidden(self):\n",
    "        hidden = torch.zeros(self.num_layers*2 if self.bidirectional else self.num_layers,\n",
    "                             self.batch_size, self.hidden_dim//2)\n",
    "        cell = torch.zeros(self.num_layers*2 if self.bidirectional else self.num_layers,\n",
    "                             self.batch_size, self.hidden_dim//2)\n",
    "        return hidden, cell\n",
    "\n",
    "    def forward(self, sent, sent_len):\n",
    "        \"\"\"\n",
    "\n",
    "        :param sent: 输入的已转换为token_id的句子，(batch_len * sent_len * token_emb_len)\n",
    "        :param sent_len: tensor(list(int))\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        embeds = self.word_embeds(sent)\n",
    "        embed_packed = pack_padded_sequence(embeds, lengths=sent_len.to('cpu'),\n",
    "                                            batch_first=True,\n",
    "                                            enforce_sorted=False)\n",
    "        lstm_out, (hidden, cell) = self.lstm(embed_packed) #, self.hidden_init)\n",
    "        lstm_out, lens = pad_packed_sequence(lstm_out, batch_first=True)\n",
    "        tag_score = self.hidden2tag1(lstm_out)\n",
    "        tag_score = self.dropout010(tag_score)\n",
    "        tag_score = self.hidden2tag2(tag_score)\n",
    "#         tag_score = nn.functional.softmax(tag_score, dim=-1)\n",
    "        return tag_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'V2-Emb=Glove300-bilstmLayer=1Hidden=200Dropout0.1Batch=32Learn=1e-1'\n",
    "model_lstm = GLove_BiLSTM(config=Config, embedding_weight=glove_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm = model_lstm.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of GLove_BiLSTM(\n",
       "  (word_embeds): Embedding(30289, 300)\n",
       "  (lstm): LSTM(300, 50, bidirectional=True)\n",
       "  (hidden2tag1): Linear(in_features=100, out_features=27, bias=True)\n",
       "  (hidden2tag2): Linear(in_features=27, out_features=9, bias=True)\n",
       "  (dropout010): Dropout(p=0.1, inplace=False)\n",
       "  (dropout020): Dropout(p=0.2, inplace=False)\n",
       "  (crf): CRF(num_tags=9)\n",
       ")>"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lstm.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 3.5792683998664065), (0, 0.1334168085220698), (7, 6.580731691551936), (1, 3.4279629629629627), (2, 4.996589124460149), (5, 3.1687052598817305), (4, 6.108141348692104), (8, 19.58835978835979), (6, 19.554499183712664)]\n"
     ]
    }
   ],
   "source": [
    "# 手动计算验证权重\n",
    "import collections\n",
    "ner_tags_all = torch.cat(dataset_conll2003_train['ner_tags'])\n",
    "t=collections.Counter(ner_tags_all.numpy())\n",
    "res = []\n",
    "for k in t:\n",
    "    res.append((k, len(ner_tags_all)/9/t[k]))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1334,  3.4280,  4.9966,  3.5793,  6.1081,  3.1687, 19.5545,  6.5807,\n",
       "        19.5884])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights=sklearn.utils.class_weight.compute_class_weight(\n",
    "    class_weight='balanced',classes=np.unique(ner_tags_all),y=ner_tags_all.numpy())\n",
    "class_weights=torch.tensor(class_weights,dtype=torch.float)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model_lstm.parameters(), lr=1e-1)\n",
    "loss_fn = nn.CrossEntropyLoss(reduction='mean', weight=class_weights.cuda()) \n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_single_epoch(model, data_iter=None, optimizer=None, loss_fn=None, is_train=False):\n",
    "    if is_train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()   \n",
    "    correct_curr, correct_sum, loss_sum, loss_curr = 0, 0, 0, 0\n",
    "    loss_list, accuracy_list = [], []\n",
    "    print('Total (training) batch = {}'.format(len(data_iter)))\n",
    "    batch_i = 0\n",
    "    data_iter_len = data_iter.dataset.__len__() # total sample num.\n",
    "    batch_num = len(data_iter)\n",
    "    \n",
    "    batch_loss_list = list()\n",
    "    logits_list = list()\n",
    "    y_list, y_len_list = [], []\n",
    "    for batch_data in data_iter:\n",
    "        torch.cuda.empty_cache()\n",
    "        batch_i += 1\n",
    "        if is_train:\n",
    "            optimizer.zero_grad()\n",
    "#             model.zero_grad()\n",
    "        x, x_len, y, y_len, _ = batch_data\n",
    "        x = x.cuda()\n",
    "        x_len = x_len.cuda()\n",
    "        y = y.cuda()\n",
    "        # model predict \n",
    "        logits = model(x, x_len)\n",
    "        assert logits.shape[0:2]==x.shape[0:2]\n",
    "        # compute loss \n",
    "        batch_loss = 0\n",
    "        for i in range(logits.size(0)): # num of samples in one batch\n",
    "            loss = loss_fn(logits[i], y[i])\n",
    "            batch_loss += loss \n",
    "        \n",
    "        batch_loss /= logits.size(0)\n",
    "        if is_train:\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # 记录\n",
    "        batch_loss_list.append(batch_loss.item())\n",
    "        logits_list.append(logits)\n",
    "        y_list.append(y)\n",
    "        y_len_list.append(y_len)\n",
    "#         if batch_i%100==0:\n",
    "#             print(batch_loss.item())\n",
    "        \n",
    "        x = x.cpu()\n",
    "        x_len = x_len.cpu()\n",
    "        y = y.cpu()\n",
    "        \n",
    "#     print(sum(batch_loss_list)/batch_num)\n",
    "    return batch_loss_list, logits_list, y_list, y_len_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_eval(model, data_iter=None, loss_fn=None):\n",
    "    model.eval()\n",
    "    correct_curr, correct_sum, loss_sum, loss_curr = 0, 0, 0, 0\n",
    "    loss_list, accuracy_list = [], []\n",
    "    print('Total (training) batch = {}'.format(len(data_iter)))\n",
    "    batch_i = 0\n",
    "    data_iter_len = data_iter.dataset.__len__() # total sample num.\n",
    "    batch_num = len(data_iter)\n",
    "    \n",
    "    batch_loss_list = list()\n",
    "    logits_list = list()\n",
    "    y_list, y_len_list = [], []\n",
    "    for batch_data in data_iter:\n",
    "        batch_i += 1\n",
    "        x, x_len, y, y_len,_ = batch_data\n",
    "        x = x.cuda()\n",
    "        x_len = x_len.cuda()\n",
    "        y = y.cuda()\n",
    "        # model predict \n",
    "        logits = model(x, x_len)\n",
    "        assert logits.shape[0:2]==x.shape[0:2]\n",
    "        # compute loss \n",
    "        batch_loss = 0\n",
    "        for i in range(logits.size(0)): # num of samples in one batch\n",
    "            loss = loss_fn(logits[i], y[i])\n",
    "            batch_loss += loss \n",
    "        \n",
    "        batch_loss /= logits.size(0)\n",
    "        \n",
    "        # 记录\n",
    "        batch_loss_list.append(batch_loss.item())\n",
    "        logits_list.append(logits)\n",
    "        y_list.append(y)\n",
    "        y_len_list.append(y_len)\n",
    "#         if batch_i%100==0:\n",
    "#             print(batch_loss.item())\n",
    "        \n",
    "        x = x.cpu()\n",
    "        x_len = x_len.cpu()\n",
    "        y = y.cpu()\n",
    "        \n",
    "#     print(sum(batch_loss_list)/batch_num)\n",
    "    return batch_loss_list, logits_list, y_list, y_len_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练开始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Epoch = 0\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.64664103\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.62670536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/web_server/antispam/project/kml_public/liuguizhou/my_train/POS/conll2003/MyFunctions2.py:24: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  assert sum(mask.sum(axis=1) == y_len_list[logit_i]) // batch_len == 1\n",
      "  2%|▏         | 1/50 [01:14<1:00:50, 74.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 67.98%, precision = 59.16%, accuracy = 86.80%\n",
      "Test metrics\n",
      "recall = 66.32%, precision = 62.99%, accuracy = 87.31%\n",
      "==================================================\n",
      "Epoch = 1\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.46238990\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.45559920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [02:34<1:02:09, 77.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 76.53%, precision = 66.94%, accuracy = 89.76%\n",
      "Test metrics\n",
      "recall = 77.56%, precision = 66.85%, accuracy = 89.36%\n",
      "==================================================\n",
      "Epoch = 2\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.37181192\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.48400327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [04:26<1:13:04, 93.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 80.44%, precision = 70.85%, accuracy = 91.20%\n",
      "Test metrics\n",
      "recall = 78.90%, precision = 68.57%, accuracy = 89.99%\n",
      "==================================================\n",
      "Epoch = 3\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.33776038\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.44892061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [05:44<1:07:05, 87.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 82.58%, precision = 73.46%, accuracy = 92.10%\n",
      "Test metrics\n",
      "recall = 77.19%, precision = 71.30%, accuracy = 90.59%\n",
      "==================================================\n",
      "Epoch = 4\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.28626353\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.39135029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [07:03<1:03:12, 84.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 84.48%, precision = 75.71%, accuracy = 92.87%\n",
      "Test metrics\n",
      "recall = 80.70%, precision = 73.87%, accuracy = 91.64%\n",
      "==================================================\n",
      "Epoch = 5\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.25619031\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.47189575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [08:22<1:00:29, 82.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 86.37%, precision = 77.10%, accuracy = 93.43%\n",
      "Test metrics\n",
      "recall = 79.50%, precision = 72.15%, accuracy = 91.06%\n",
      "==================================================\n",
      "Epoch = 6\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.23247127\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.46635179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [09:40<57:58, 80.89s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 87.46%, precision = 78.36%, accuracy = 93.87%\n",
      "Test metrics\n",
      "recall = 80.56%, precision = 70.40%, accuracy = 90.69%\n",
      "==================================================\n",
      "Epoch = 7\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.20809575\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.42242485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [10:57<55:55, 79.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 88.29%, precision = 79.53%, accuracy = 94.24%\n",
      "Test metrics\n",
      "recall = 81.19%, precision = 77.90%, accuracy = 92.69%\n",
      "==================================================\n",
      "Epoch = 8\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.18775487\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.40796615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [12:15<54:01, 79.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 89.29%, precision = 80.30%, accuracy = 94.55%\n",
      "Test metrics\n",
      "recall = 83.63%, precision = 73.55%, accuracy = 91.89%\n",
      "==================================================\n",
      "Epoch = 9\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.16998234\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.39200763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [13:31<52:09, 78.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 90.20%, precision = 81.01%, accuracy = 94.83%\n",
      "Test metrics\n",
      "recall = 83.26%, precision = 71.61%, accuracy = 91.31%\n",
      "==================================================\n",
      "Epoch = 10\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.14467941\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.39120234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [14:49<50:49, 78.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 91.59%, precision = 83.16%, accuracy = 95.49%\n",
      "Test metrics\n",
      "recall = 84.17%, precision = 73.51%, accuracy = 91.94%\n",
      "==================================================\n",
      "Epoch = 11\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.13406960\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.41049089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [16:07<49:27, 78.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 92.26%, precision = 83.69%, accuracy = 95.70%\n",
      "Test metrics\n",
      "recall = 84.07%, precision = 76.91%, accuracy = 92.81%\n",
      "==================================================\n",
      "Epoch = 12\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.12039667\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.39696844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [17:24<48:03, 77.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 92.92%, precision = 84.39%, accuracy = 95.94%\n",
      "Test metrics\n",
      "recall = 84.50%, precision = 81.66%, accuracy = 93.98%\n",
      "==================================================\n",
      "Epoch = 13\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.10675489\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.39240250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [18:44<47:05, 78.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 93.59%, precision = 85.46%, accuracy = 96.27%\n",
      "Test metrics\n",
      "recall = 85.18%, precision = 86.03%, accuracy = 95.00%\n",
      "==================================================\n",
      "Epoch = 14\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.09331839\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.42473321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [20:02<45:43, 78.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 94.47%, precision = 86.03%, accuracy = 96.51%\n",
      "Test metrics\n",
      "recall = 85.37%, precision = 80.39%, accuracy = 93.81%\n",
      "==================================================\n",
      "Epoch = 15\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.08489478\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.40222281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [21:21<44:28, 78.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 94.86%, precision = 86.90%, accuracy = 96.75%\n",
      "Test metrics\n",
      "recall = 86.39%, precision = 80.17%, accuracy = 93.89%\n",
      "==================================================\n",
      "Epoch = 16\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.07667232\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.42810756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [22:42<43:32, 79.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 95.34%, precision = 87.75%, accuracy = 97.00%\n",
      "Test metrics\n",
      "recall = 85.39%, precision = 80.29%, accuracy = 93.79%\n",
      "==================================================\n",
      "Epoch = 17\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.06986865\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.44154893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [24:03<42:32, 79.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 95.61%, precision = 87.95%, accuracy = 97.07%\n",
      "Test metrics\n",
      "recall = 85.66%, precision = 81.69%, accuracy = 94.14%\n",
      "==================================================\n",
      "Epoch = 18\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.06533102\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.44681665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [25:24<41:24, 80.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 96.11%, precision = 88.53%, accuracy = 97.27%\n",
      "Test metrics\n",
      "recall = 85.56%, precision = 81.18%, accuracy = 94.01%\n",
      "==================================================\n",
      "Epoch = 19\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.05880184\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.45055562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [26:44<40:05, 80.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 96.59%, precision = 89.60%, accuracy = 97.55%\n",
      "Test metrics\n",
      "recall = 85.33%, precision = 83.33%, accuracy = 94.45%\n",
      "==================================================\n",
      "Epoch = 20\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.05520717\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.45010391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [28:02<38:27, 79.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 96.62%, precision = 89.76%, accuracy = 97.59%\n",
      "Test metrics\n",
      "recall = 86.17%, precision = 82.70%, accuracy = 94.44%\n",
      "==================================================\n",
      "Epoch = 21\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.05183696\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.46521300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [29:21<37:00, 79.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 96.98%, precision = 90.35%, accuracy = 97.76%\n",
      "Test metrics\n",
      "recall = 85.36%, precision = 83.85%, accuracy = 94.57%\n",
      "==================================================\n",
      "Epoch = 22\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.04795017\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.46559654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [30:40<35:36, 79.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 97.13%, precision = 90.75%, accuracy = 97.86%\n",
      "Test metrics\n",
      "recall = 85.32%, precision = 82.04%, accuracy = 94.17%\n",
      "==================================================\n",
      "Epoch = 23\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.04543529\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.48102297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [31:58<34:11, 78.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 97.33%, precision = 91.23%, accuracy = 97.99%\n",
      "Test metrics\n",
      "recall = 85.42%, precision = 84.13%, accuracy = 94.64%\n",
      "==================================================\n",
      "Epoch = 24\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.04250730\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.49590592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [33:17<32:49, 78.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 97.49%, precision = 91.58%, accuracy = 98.08%\n",
      "Test metrics\n",
      "recall = 85.24%, precision = 85.42%, accuracy = 94.88%\n",
      "==================================================\n",
      "Epoch = 25\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.04000681\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.51627618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [34:36<31:31, 78.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 97.62%, precision = 91.81%, accuracy = 98.15%\n",
      "Test metrics\n",
      "recall = 85.19%, precision = 85.45%, accuracy = 94.88%\n",
      "==================================================\n",
      "Epoch = 26\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.03922533\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.52355871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [35:54<30:09, 78.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 97.80%, precision = 91.84%, accuracy = 98.18%\n",
      "Test metrics\n",
      "recall = 85.17%, precision = 85.20%, accuracy = 94.83%\n",
      "==================================================\n",
      "Epoch = 27\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.03758795\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.52684869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [37:12<28:48, 78.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 97.81%, precision = 92.27%, accuracy = 98.26%\n",
      "Test metrics\n",
      "recall = 84.59%, precision = 83.57%, accuracy = 94.40%\n",
      "==================================================\n",
      "Epoch = 28\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.03588254\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.52800783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [38:30<27:27, 78.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 97.83%, precision = 92.33%, accuracy = 98.28%\n",
      "Test metrics\n",
      "recall = 85.21%, precision = 85.36%, accuracy = 94.86%\n",
      "==================================================\n",
      "Epoch = 29\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.03514667\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.51880845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [39:48<26:01, 78.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 97.94%, precision = 92.60%, accuracy = 98.35%\n",
      "Test metrics\n",
      "recall = 85.28%, precision = 85.12%, accuracy = 94.83%\n",
      "==================================================\n",
      "Epoch = 30\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.03276230\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.53211197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [41:06<24:46, 78.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 98.05%, precision = 92.92%, accuracy = 98.43%\n",
      "Test metrics\n",
      "recall = 85.23%, precision = 83.94%, accuracy = 94.57%\n",
      "==================================================\n",
      "Epoch = 31\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.03155658\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.54606416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [42:24<23:26, 78.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 98.10%, precision = 92.96%, accuracy = 98.44%\n",
      "Test metrics\n",
      "recall = 84.94%, precision = 84.34%, accuracy = 94.61%\n",
      "==================================================\n",
      "Epoch = 32\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.03094440\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.54473807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [43:43<22:09, 78.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 98.13%, precision = 93.28%, accuracy = 98.51%\n",
      "Test metrics\n",
      "recall = 84.89%, precision = 84.79%, accuracy = 94.70%\n",
      "==================================================\n",
      "Epoch = 33\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.02986412\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.55372753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [45:01<20:52, 78.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 98.26%, precision = 93.50%, accuracy = 98.57%\n",
      "Test metrics\n",
      "recall = 84.86%, precision = 84.97%, accuracy = 94.73%\n",
      "==================================================\n",
      "Epoch = 34\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.02914496\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.55465478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [46:19<19:34, 78.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 98.24%, precision = 93.48%, accuracy = 98.56%\n",
      "Test metrics\n",
      "recall = 84.89%, precision = 85.56%, accuracy = 94.86%\n",
      "==================================================\n",
      "Epoch = 35\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.02840826\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.56565432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [47:37<18:15, 78.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 98.31%, precision = 93.64%, accuracy = 98.60%\n",
      "Test metrics\n",
      "recall = 85.15%, precision = 85.38%, accuracy = 94.86%\n",
      "==================================================\n",
      "Epoch = 36\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.02752865\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.56520050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [48:56<16:58, 78.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 98.36%, precision = 93.93%, accuracy = 98.66%\n",
      "Test metrics\n",
      "recall = 84.80%, precision = 85.14%, accuracy = 94.76%\n",
      "==================================================\n",
      "Epoch = 37\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.02631487\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.57705844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [50:15<15:43, 78.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 98.43%, precision = 94.07%, accuracy = 98.70%\n",
      "Test metrics\n",
      "recall = 84.92%, precision = 85.04%, accuracy = 94.76%\n",
      "==================================================\n",
      "Epoch = 38\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.02651458\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.58233475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [51:35<14:27, 78.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 98.41%, precision = 93.87%, accuracy = 98.66%\n",
      "Test metrics\n",
      "recall = 84.69%, precision = 85.37%, accuracy = 94.79%\n",
      "==================================================\n",
      "Epoch = 39\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.02542383\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.57470455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [52:53<13:06, 78.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 98.47%, precision = 94.20%, accuracy = 98.73%\n",
      "Test metrics\n",
      "recall = 85.00%, precision = 85.32%, accuracy = 94.83%\n",
      "==================================================\n",
      "Epoch = 40\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.02506385\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.58952046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [54:12<11:47, 78.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 98.47%, precision = 94.18%, accuracy = 98.73%\n",
      "Test metrics\n",
      "recall = 84.60%, precision = 86.23%, accuracy = 94.95%\n",
      "==================================================\n",
      "Epoch = 41\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.02533092\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.58582595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [55:30<10:28, 78.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 98.52%, precision = 94.41%, accuracy = 98.78%\n",
      "Test metrics\n",
      "recall = 84.57%, precision = 85.68%, accuracy = 94.83%\n",
      "==================================================\n",
      "Epoch = 42\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.02494000\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.59071458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [56:48<09:09, 78.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 98.55%, precision = 94.34%, accuracy = 98.77%\n",
      "Test metrics\n",
      "recall = 84.70%, precision = 86.41%, accuracy = 95.00%\n",
      "==================================================\n",
      "Epoch = 43\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.02422787\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.59459202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [58:07<07:51, 78.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 98.58%, precision = 94.61%, accuracy = 98.82%\n",
      "Test metrics\n",
      "recall = 84.78%, precision = 86.29%, accuracy = 94.99%\n",
      "==================================================\n",
      "Epoch = 44\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.02351872\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.59768528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [59:24<06:30, 78.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 98.62%, precision = 94.67%, accuracy = 98.84%\n",
      "Test metrics\n",
      "recall = 84.75%, precision = 86.06%, accuracy = 94.94%\n",
      "==================================================\n",
      "Epoch = 45\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.02389830\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.59969714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [1:00:05<04:27, 66.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 98.60%, precision = 94.62%, accuracy = 98.83%\n",
      "Test metrics\n",
      "recall = 84.86%, precision = 85.87%, accuracy = 94.92%\n",
      "==================================================\n",
      "Epoch = 46\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.02344542\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.60506356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [1:00:17<02:31, 50.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 98.60%, precision = 94.58%, accuracy = 98.82%\n",
      "Test metrics\n",
      "recall = 84.64%, precision = 86.03%, accuracy = 94.92%\n",
      "==================================================\n",
      "Epoch = 47\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.02295291\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.59968222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [1:00:30<01:18, 39.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 98.68%, precision = 94.65%, accuracy = 98.85%\n",
      "Test metrics\n",
      "recall = 84.63%, precision = 86.18%, accuracy = 94.94%\n",
      "==================================================\n",
      "Epoch = 48\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.02253207\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.60300491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [1:00:44<00:31, 31.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 98.65%, precision = 94.67%, accuracy = 98.85%\n",
      "Test metrics\n",
      "recall = 84.69%, precision = 86.44%, accuracy = 95.00%\n",
      "==================================================\n",
      "Epoch = 49\n",
      "==================================================\n",
      "Total (training) batch = 439\n",
      "training loss = 0.02259921\n",
      "Total (training) batch = 108\n",
      "testing loss = 0.60232710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [1:00:58<00:00, 73.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "recall = 98.70%, precision = 94.87%, accuracy = 98.89%\n",
      "Test metrics\n",
      "recall = 84.66%, precision = 86.14%, accuracy = 94.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "precision_test_max, precision_test_curr = 0, 0\n",
    "\n",
    "for epoch in tqdm(range(50)):\n",
    "    print('='*50)\n",
    "    print('Epoch = {}'.format(epoch))\n",
    "    print('='*50)\n",
    "    batch_loss_list, logits_list, y_list, y_len_list = train_eval_single_epoch(model_lstm, \n",
    "                                                                               dataset_conll2003_train_loader, \n",
    "                                                                               optimizer=optimizer,\n",
    "                                                                               loss_fn=loss_fn,\n",
    "                                                                               is_train=True)\n",
    "    scheduler.step() # 加上后好一些\n",
    "    print('training loss = {:.8f}'.format(sum(batch_loss_list)/len(batch_loss_list)))\n",
    "    test_batch_loss_list, test_logits_list, test_y_list, test_y_len_list = func_eval(model_lstm, \n",
    "                                                                               dataset_conll2003_test_loader, \n",
    "                                                                               loss_fn=loss_fn)\n",
    "    print('testing loss = {:.8f}'.format(sum(test_batch_loss_list)/len(test_batch_loss_list)))\n",
    "    \n",
    "    # 评估\n",
    "    train_dict = MyTools.func_cal_accu_recall(logits_list=logits_list, y_list=y_list, y_len_list=y_len_list)\n",
    "    test_dict = MyTools.func_cal_accu_recall(logits_list=test_logits_list, y_list=test_y_list, \n",
    "                                             y_len_list=test_y_len_list)\n",
    "    \n",
    "    print('Train metrics')\n",
    "    train_metric = MyTools.func_cal_metrics(train_dict)\n",
    "    print('Test metrics')\n",
    "    test_metric = MyTools.func_cal_metrics(test_dict)\n",
    "    \n",
    "    # save model if current f1 rate is better than previous ones\n",
    "    recall_test_curr, precision_test_curr, accuracy_test_curr = test_metric\n",
    "    if precision_test_curr > precision_test_max:\n",
    "        torch.save(model_lstm.state_dict(), './models/model_v2_'+model_name+'epoch='+str(epoch)+\n",
    "                   'accu='+str(round(accuracy_test_curr,4))+\n",
    "                   'recall='+str(round(recall_test_curr,4))+\n",
    "                   'precision='+str(round(precision_test_curr,4)))\n",
    "    precision_test_max = max(precision_test_curr, precision_test_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练总结\n",
    "\n",
    "加载预训练emb果然是效果突出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch = 1\n",
    "Train metrics\n",
    "recall = 67.98%, precision = 59.16%, accuracy = 86.80%\n",
    "Test metrics\n",
    "recall = 66.32%, precision = 62.99%, accuracy = 87.31%\n",
    "\n",
    "Epoch = 49\n",
    "Train metrics\n",
    "recall = 98.70%, precision = 94.87%, accuracy = 98.89%\n",
    "Test metrics\n",
    "recall = 84.66%, precision = 86.14%, accuracy = 94.94%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型加载及结果探查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm_load = BiLSTM_CRF(config=Config)\n",
    "model_lstm_load.load_state_dict(torch.load('./models/model_v0_V0-Embrand200-bilstm1Layer200Hidden16Batch1e-3Learnepoch=27accu=0.835210509314095recall=0.9078498293515358F1=0.43500830208429403'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=next(iter(dataset_conll2003_test_loader))\n",
    "print(t)\n",
    "model_lstm_load.cuda()\n",
    "model_lstm_load.eval()\n",
    "y = t[2]\n",
    "res = model_lstm_load(t[0].cuda(), t[1].cuda())\n",
    "res_arg = torch.argmax(res, dim=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 案例探查总结\n",
    "\n",
    "一些误判如下：\n",
    "- 一些容易修正的误判（加规则或者加CRF）\n",
    "'s, y: O, predict: I-ORG\n",
    "\n",
    "- 地点误判为机构\n",
    "United, y: B-LOC, predict: I-ORG Arab, y: I-LOC, predict: I-LOC Emirates, y: I-LOC, predict: I-ORG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# true value\n",
    "y_ner_list = []\n",
    "for sent in y:\n",
    "    tmp = []\n",
    "    for token in sent:\n",
    "        tmp.append(ner_id2tag[token.item()])\n",
    "    y_ner_list.append(tmp)\n",
    "\n",
    "# predict\n",
    "res_ner_list = []\n",
    "for sent in res_arg:\n",
    "    tmp = []\n",
    "    for token in sent:\n",
    "        tmp.append(ner_id2tag[token.item()])\n",
    "    res_ner_list.append(tmp)\n",
    "\n",
    "for i, sent in enumerate(t[4]):\n",
    "    print('='*50)\n",
    "    for j, token in enumerate(sent):\n",
    "        print('{}, y: {}, predict: {}'.format(token, y_ner_list[i][j], res_ner_list[i][j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
