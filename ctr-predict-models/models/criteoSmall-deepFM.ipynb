{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr.models import DeepFM\n",
    "from deepctr.feature_column import SparseFeat, DenseFeat,get_feature_names\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "\n",
    "data_path = '../data/ctr-criteo-small-data/train_1m.txt'\n",
    "# 数据说明：https://www.kaggle.com/competitions/criteo-display-ad-challenge/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 40)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(data_path, sep='\\t', header=None)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=0.5) # 小取样，跑通"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 规定\n",
    "dense_features = ['I'+str(i+1) for i in range(13)]\n",
    "sparse_features = ['C'+str(i+1) for i in range(26)]\n",
    "cols = ['label'] + dense_features + sparse_features\n",
    "# 其中C1-C26是Category的特征(sparse_features)，而I1-I13是连续的特征(dense_features)。\n",
    "data.columns = cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 因为有缺失的值，我们把Category的缺失值设置为”-1”，而把连续的缺失值设置为0。\n",
    "data[sparse_features] = data[sparse_features].fillna('-1')\n",
    "data[dense_features] = data[dense_features].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 类别型的encoder\n",
    "for col in sparse_features:\n",
    "    enc = LabelEncoder()\n",
    "    data[col] = enc.fit_transform(data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 连续值：缩放到0-1范围\n",
    "mms = MinMaxScaler(feature_range=(0,1))\n",
    "data[dense_features] = mms.fit_transform(data[dense_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构造deepFM的emb层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixlen_feature_columns = [SparseFeat(feat, vocabulary_size=data[feat].max() + 1,embedding_dim=4) \n",
    "                          for i,feat in enumerate(sparse_features)] + [DenseFeat(feat, 1,)for feat in dense_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseFeat(name='C1', vocabulary_size=1048, embedding_dim=4, use_hash=False, vocabulary_path=None, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7fcba4ad7e90>, embedding_name='C1', group_name='default_group', trainable=True)\n",
      "\n",
      "\n",
      "SparseFeat(name='C2', vocabulary_size=526, embedding_dim=4, use_hash=False, vocabulary_path=None, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7fcba4ad7410>, embedding_name='C2', group_name='default_group', trainable=True)\n",
      "\n",
      "\n",
      "SparseFeat(name='C3', vocabulary_size=176296, embedding_dim=4, use_hash=False, vocabulary_path=None, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7fcba4ad77d0>, embedding_name='C3', group_name='default_group', trainable=True)\n",
      "\n",
      "\n",
      "SparseFeat(name='C4', vocabulary_size=74497, embedding_dim=4, use_hash=False, vocabulary_path=None, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7fcb9c3ae190>, embedding_name='C4', group_name='default_group', trainable=True)\n",
      "\n",
      "\n",
      "SparseFeat(name='C5', vocabulary_size=224, embedding_dim=4, use_hash=False, vocabulary_path=None, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7fcb9c3aeb50>, embedding_name='C5', group_name='default_group', trainable=True)\n",
      "\n",
      "\n",
      "SparseFeat(name='C6', vocabulary_size=14, embedding_dim=4, use_hash=False, vocabulary_path=None, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7fcb9c3ae6d0>, embedding_name='C6', group_name='default_group', trainable=True)\n",
      "\n",
      "\n",
      "SparseFeat(name='C7', vocabulary_size=10225, embedding_dim=4, use_hash=False, vocabulary_path=None, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7fcb9c3ae750>, embedding_name='C7', group_name='default_group', trainable=True)\n",
      "\n",
      "\n",
      "SparseFeat(name='C8', vocabulary_size=476, embedding_dim=4, use_hash=False, vocabulary_path=None, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7fcb9c3ae250>, embedding_name='C8', group_name='default_group', trainable=True)\n",
      "\n",
      "\n",
      "SparseFeat(name='C9', vocabulary_size=3, embedding_dim=4, use_hash=False, vocabulary_path=None, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7fcc904794d0>, embedding_name='C9', group_name='default_group', trainable=True)\n",
      "\n",
      "\n",
      "SparseFeat(name='C10', vocabulary_size=23721, embedding_dim=4, use_hash=False, vocabulary_path=None, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7fcc904793d0>, embedding_name='C10', group_name='default_group', trainable=True)\n",
      "\n",
      "\n",
      "SparseFeat(name='C11', vocabulary_size=4527, embedding_dim=4, use_hash=False, vocabulary_path=None, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7fcc90479050>, embedding_name='C11', group_name='default_group', trainable=True)\n",
      "\n",
      "\n",
      "SparseFeat(name='C12', vocabulary_size=149946, embedding_dim=4, use_hash=False, vocabulary_path=None, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7fcc904c30d0>, embedding_name='C12', group_name='default_group', trainable=True)\n",
      "\n",
      "\n",
      "SparseFeat(name='C13', vocabulary_size=3025, embedding_dim=4, use_hash=False, vocabulary_path=None, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7fcc904c3310>, embedding_name='C13', group_name='default_group', trainable=True)\n",
      "\n",
      "\n",
      "SparseFeat(name='C14', vocabulary_size=26, embedding_dim=4, use_hash=False, vocabulary_path=None, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7fcc904c33d0>, embedding_name='C14', group_name='default_group', trainable=True)\n",
      "\n",
      "\n",
      "SparseFeat(name='C15', vocabulary_size=7776, embedding_dim=4, use_hash=False, vocabulary_path=None, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7fcc904c3190>, embedding_name='C15', group_name='default_group', trainable=True)\n",
      "\n",
      "\n",
      "SparseFeat(name='C16', vocabulary_size=118210, embedding_dim=4, use_hash=False, vocabulary_path=None, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7fcb9c37ec90>, embedding_name='C16', group_name='default_group', trainable=True)\n",
      "\n",
      "\n",
      "SparseFeat(name='C17', vocabulary_size=10, embedding_dim=4, use_hash=False, vocabulary_path=None, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7fcb9c37e390>, embedding_name='C17', group_name='default_group', trainable=True)\n",
      "\n",
      "\n",
      "SparseFeat(name='C18', vocabulary_size=3488, embedding_dim=4, use_hash=False, vocabulary_path=None, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7fcb9c37e3d0>, embedding_name='C18', group_name='default_group', trainable=True)\n",
      "\n",
      "\n",
      "SparseFeat(name='C19', vocabulary_size=1707, embedding_dim=4, use_hash=False, vocabulary_path=None, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7fcb9c37ed90>, embedding_name='C19', group_name='default_group', trainable=True)\n",
      "\n",
      "\n",
      "SparseFeat(name='C20', vocabulary_size=4, embedding_dim=4, use_hash=False, vocabulary_path=None, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7fcb9c37e2d0>, embedding_name='C20', group_name='default_group', trainable=True)\n",
      "\n",
      "\n",
      "SparseFeat(name='C21', vocabulary_size=135930, embedding_dim=4, use_hash=False, vocabulary_path=None, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7fcb9c37e810>, embedding_name='C21', group_name='default_group', trainable=True)\n",
      "\n",
      "\n",
      "SparseFeat(name='C22', vocabulary_size=15, embedding_dim=4, use_hash=False, vocabulary_path=None, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7fcb9c37e750>, embedding_name='C22', group_name='default_group', trainable=True)\n",
      "\n",
      "\n",
      "SparseFeat(name='C23', vocabulary_size=15, embedding_dim=4, use_hash=False, vocabulary_path=None, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7fcb9c37e150>, embedding_name='C23', group_name='default_group', trainable=True)\n",
      "\n",
      "\n",
      "SparseFeat(name='C24', vocabulary_size=28755, embedding_dim=4, use_hash=False, vocabulary_path=None, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7fcb9c37e210>, embedding_name='C24', group_name='default_group', trainable=True)\n",
      "\n",
      "\n",
      "SparseFeat(name='C25', vocabulary_size=66, embedding_dim=4, use_hash=False, vocabulary_path=None, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7fcb9c37e190>, embedding_name='C25', group_name='default_group', trainable=True)\n",
      "\n",
      "\n",
      "SparseFeat(name='C26', vocabulary_size=22024, embedding_dim=4, use_hash=False, vocabulary_path=None, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7fcb9c37e090>, embedding_name='C26', group_name='default_group', trainable=True)\n",
      "\n",
      "\n",
      "DenseFeat(name='I1', dimension=1, dtype='float32', transform_fn=None)\n",
      "\n",
      "\n",
      "DenseFeat(name='I2', dimension=1, dtype='float32', transform_fn=None)\n",
      "\n",
      "\n",
      "DenseFeat(name='I3', dimension=1, dtype='float32', transform_fn=None)\n",
      "\n",
      "\n",
      "DenseFeat(name='I4', dimension=1, dtype='float32', transform_fn=None)\n",
      "\n",
      "\n",
      "DenseFeat(name='I5', dimension=1, dtype='float32', transform_fn=None)\n",
      "\n",
      "\n",
      "DenseFeat(name='I6', dimension=1, dtype='float32', transform_fn=None)\n",
      "\n",
      "\n",
      "DenseFeat(name='I7', dimension=1, dtype='float32', transform_fn=None)\n",
      "\n",
      "\n",
      "DenseFeat(name='I8', dimension=1, dtype='float32', transform_fn=None)\n",
      "\n",
      "\n",
      "DenseFeat(name='I9', dimension=1, dtype='float32', transform_fn=None)\n",
      "\n",
      "\n",
      "DenseFeat(name='I10', dimension=1, dtype='float32', transform_fn=None)\n",
      "\n",
      "\n",
      "DenseFeat(name='I11', dimension=1, dtype='float32', transform_fn=None)\n",
      "\n",
      "\n",
      "DenseFeat(name='I12', dimension=1, dtype='float32', transform_fn=None)\n",
      "\n",
      "\n",
      "DenseFeat(name='I13', dimension=1, dtype='float32', transform_fn=None)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in fixlen_feature_columns:\n",
    "    print(i)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deepctr.feature_column.SparseFeat"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(fixlen_feature_columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 线性部分以及DNN部分\n",
    "dnn_feature_columns = fixlen_feature_columns\n",
    "linear_feature_columns = fixlen_feature_columns\n",
    "\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型构造"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['label',]\n",
    "train_model_input = {name:train[name].values for name in feature_names}\n",
    "test_model_input = {name:test[name].values for name in feature_names}\n",
    "\n",
    "model = DeepFM(linear_feature_columns,dnn_feature_columns,task='binary') # 规定了linear、dnn的输入\n",
    "model.compile(\"adam\", \"binary_crossentropy\",metrics=['binary_crossentropy'], ) # 二分类、交叉熵损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练10轮"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1250/1250 - 50s - loss: 0.4943 - binary_crossentropy: 0.4903 - val_loss: 0.4851 - val_binary_crossentropy: 0.4768\n",
      "Epoch 2/10\n",
      "1250/1250 - 43s - loss: 0.3876 - binary_crossentropy: 0.3744 - val_loss: 0.5615 - val_binary_crossentropy: 0.5447\n",
      "Epoch 3/10\n",
      "1250/1250 - 43s - loss: 0.3404 - binary_crossentropy: 0.3216 - val_loss: 0.5951 - val_binary_crossentropy: 0.5753\n",
      "Epoch 4/10\n",
      "1250/1250 - 43s - loss: 0.2819 - binary_crossentropy: 0.2634 - val_loss: 0.7555 - val_binary_crossentropy: 0.7376\n",
      "Epoch 5/10\n",
      "1250/1250 - 43s - loss: 0.2471 - binary_crossentropy: 0.2300 - val_loss: 0.8690 - val_binary_crossentropy: 0.8519\n",
      "Epoch 6/10\n",
      "1250/1250 - 43s - loss: 0.2235 - binary_crossentropy: 0.2068 - val_loss: 0.8518 - val_binary_crossentropy: 0.8347\n",
      "Epoch 7/10\n",
      "1250/1250 - 43s - loss: 0.2058 - binary_crossentropy: 0.1890 - val_loss: 0.9306 - val_binary_crossentropy: 0.9131\n",
      "Epoch 8/10\n",
      "1250/1250 - 43s - loss: 0.1952 - binary_crossentropy: 0.1778 - val_loss: 0.8600 - val_binary_crossentropy: 0.8417\n",
      "Epoch 9/10\n",
      "1250/1250 - 42s - loss: 0.1852 - binary_crossentropy: 0.1671 - val_loss: 0.8759 - val_binary_crossentropy: 0.8568\n",
      "Epoch 10/10\n",
      "1250/1250 - 42s - loss: 0.1763 - binary_crossentropy: 0.1575 - val_loss: 0.9413 - val_binary_crossentropy: 0.9218\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_model_input, train[target].values,\n",
    "                    batch_size=256, epochs=10, verbose=2, validation_split=0.2, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ans = model.predict(test_model_input, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test LogLoss nan\n",
      "test AUC 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:2279: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:2279: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n"
     ]
    }
   ],
   "source": [
    "print(\"test LogLoss\", round(log_loss(test[target].values, pred_ans), 4))\n",
    "print(\"test AUC\", round(roc_auc_score(test[target].values, pred_ans), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 再进行30轮训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1250/1250 - 43s - loss: 0.1697 - binary_crossentropy: 0.1505 - val_loss: 0.9736 - val_binary_crossentropy: 0.9537\n",
      "Epoch 2/30\n",
      "1250/1250 - 42s - loss: 0.1649 - binary_crossentropy: 0.1454 - val_loss: 0.9228 - val_binary_crossentropy: 0.9025\n",
      "Epoch 3/30\n",
      "1250/1250 - 41s - loss: 0.1584 - binary_crossentropy: 0.1386 - val_loss: 0.9576 - val_binary_crossentropy: 0.9372\n",
      "Epoch 4/30\n",
      "1250/1250 - 42s - loss: 0.1536 - binary_crossentropy: 0.1337 - val_loss: 0.9838 - val_binary_crossentropy: 0.9633\n",
      "Epoch 5/30\n",
      "1250/1250 - 43s - loss: 0.1482 - binary_crossentropy: 0.1283 - val_loss: 0.9920 - val_binary_crossentropy: 0.9717\n",
      "Epoch 6/30\n",
      "1250/1250 - 43s - loss: 0.1445 - binary_crossentropy: 0.1246 - val_loss: 1.0744 - val_binary_crossentropy: 1.0540\n",
      "Epoch 7/30\n",
      "1250/1250 - 44s - loss: 0.1413 - binary_crossentropy: 0.1214 - val_loss: 1.0725 - val_binary_crossentropy: 1.0520\n",
      "Epoch 8/30\n",
      "1250/1250 - 46s - loss: 0.1391 - binary_crossentropy: 0.1191 - val_loss: 1.0594 - val_binary_crossentropy: 1.0387\n",
      "Epoch 9/30\n",
      "1250/1250 - 46s - loss: 0.1355 - binary_crossentropy: 0.1154 - val_loss: 1.1106 - val_binary_crossentropy: 1.0899\n",
      "Epoch 10/30\n",
      "1250/1250 - 47s - loss: 0.1333 - binary_crossentropy: 0.1131 - val_loss: 1.0830 - val_binary_crossentropy: 1.0622\n",
      "Epoch 11/30\n",
      "1250/1250 - 48s - loss: 0.1309 - binary_crossentropy: 0.1105 - val_loss: 1.0981 - val_binary_crossentropy: 1.0772\n",
      "Epoch 12/30\n",
      "1250/1250 - 48s - loss: 0.1272 - binary_crossentropy: 0.1068 - val_loss: 1.1341 - val_binary_crossentropy: 1.1133\n",
      "Epoch 13/30\n",
      "1250/1250 - 48s - loss: 0.1261 - binary_crossentropy: 0.1057 - val_loss: 1.1487 - val_binary_crossentropy: 1.1278\n",
      "Epoch 14/30\n",
      "1250/1250 - 48s - loss: 0.1239 - binary_crossentropy: 0.1034 - val_loss: 1.1684 - val_binary_crossentropy: 1.1475\n",
      "Epoch 15/30\n",
      "1250/1250 - 49s - loss: 0.1211 - binary_crossentropy: 0.1006 - val_loss: 1.1585 - val_binary_crossentropy: 1.1376\n",
      "Epoch 16/30\n",
      "1250/1250 - 49s - loss: 0.1193 - binary_crossentropy: 0.0988 - val_loss: 1.1404 - val_binary_crossentropy: 1.1194\n",
      "Epoch 17/30\n",
      "1250/1250 - 50s - loss: 0.1202 - binary_crossentropy: 0.0995 - val_loss: 1.1629 - val_binary_crossentropy: 1.1415\n",
      "Epoch 18/30\n",
      "1250/1250 - 50s - loss: 0.1174 - binary_crossentropy: 0.0966 - val_loss: 1.2221 - val_binary_crossentropy: 1.2008\n",
      "Epoch 19/30\n",
      "1250/1250 - 51s - loss: 0.1153 - binary_crossentropy: 0.0945 - val_loss: 1.1750 - val_binary_crossentropy: 1.1537\n",
      "Epoch 20/30\n",
      "1250/1250 - 51s - loss: 0.1132 - binary_crossentropy: 0.0923 - val_loss: 1.2257 - val_binary_crossentropy: 1.2044\n",
      "Epoch 21/30\n",
      "1250/1250 - 51s - loss: 0.1117 - binary_crossentropy: 0.0909 - val_loss: 1.2017 - val_binary_crossentropy: 1.1803\n",
      "Epoch 22/30\n",
      "1250/1250 - 52s - loss: 0.1106 - binary_crossentropy: 0.0898 - val_loss: 1.2722 - val_binary_crossentropy: 1.2508\n",
      "Epoch 23/30\n",
      "1250/1250 - 52s - loss: 0.1089 - binary_crossentropy: 0.0879 - val_loss: 1.2334 - val_binary_crossentropy: 1.2119\n",
      "Epoch 24/30\n",
      "1250/1250 - 52s - loss: 0.1070 - binary_crossentropy: 0.0861 - val_loss: 1.2734 - val_binary_crossentropy: 1.2520\n",
      "Epoch 25/30\n",
      "1250/1250 - 52s - loss: 0.1075 - binary_crossentropy: 0.0865 - val_loss: 1.2416 - val_binary_crossentropy: 1.2199\n",
      "Epoch 26/30\n",
      "1250/1250 - 52s - loss: 0.1052 - binary_crossentropy: 0.0840 - val_loss: 1.2223 - val_binary_crossentropy: 1.2006\n",
      "Epoch 27/30\n",
      "1250/1250 - 52s - loss: 0.1040 - binary_crossentropy: 0.0827 - val_loss: 1.2708 - val_binary_crossentropy: 1.2490\n",
      "Epoch 28/30\n",
      "1250/1250 - 52s - loss: 0.1017 - binary_crossentropy: 0.0804 - val_loss: 1.2943 - val_binary_crossentropy: 1.2726\n",
      "Epoch 29/30\n",
      "1250/1250 - 52s - loss: 0.1005 - binary_crossentropy: 0.0792 - val_loss: 1.2637 - val_binary_crossentropy: 1.2420\n",
      "Epoch 30/30\n",
      "1250/1250 - 52s - loss: 0.0991 - binary_crossentropy: 0.0779 - val_loss: 1.3113 - val_binary_crossentropy: 1.2896\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_model_input, train[target].values,\n",
    "                    batch_size=256, epochs=30, verbose=2, validation_split=0.2, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ans = model.predict(test_model_input, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test LogLoss nan\n",
      "test AUC 0.675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:2279: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:2279: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n"
     ]
    }
   ],
   "source": [
    "print(\"test LogLoss\", round(log_loss(test[target].values, pred_ans), 4))\n",
    "print(\"test AUC\", round(roc_auc_score(test[target].values, pred_ans), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 出现过拟合情况"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
